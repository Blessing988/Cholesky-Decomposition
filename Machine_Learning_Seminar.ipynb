{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Blessing988/Cholesky-Decomposition/blob/main/Machine_Learning_Seminar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWSA0xWAeJFf"
      },
      "source": [
        "# Probabilistic Reasoning and Machine Learning\n",
        "\n",
        "*Dr. Kojo Sarfo Gyamfi (Data Scientist, Twitter)*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbWlElESkyF-"
      },
      "source": [
        "> *The actual science of logic is conversant at present only with things either certain, impossible, or entirely doubtful, none of which (fortunately) we have to reason on. Therefore the true logic for this world is the calculus of Probabilities, which takes account of the magnitude of the probability which is, or ought to be, in a reasonable man's mind.*\n",
        "\n",
        "> *- James Clerk Maxwell*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ym59ZwJQLWD"
      },
      "source": [
        "## Instructions for using this notebook\n",
        "> Option 1 : If you can have internet access during the seminar (preferred):\n",
        "- Create a Google account, if you don't already have one.\n",
        "- Save a personal copy of this notebook (\"File\" --> \"Save a copy in Drive\") which you would use for the practice session.\n",
        "\n",
        "\n",
        "> Option 2: If, on the other hand, you cannot have internet access during the seminar, then go through the following steps prior to the seminar:\n",
        "- Download Anaconda from here: https://www.anaconda.com/products/individual.\n",
        "- After installing, this should install a standalone Jupyter Notebook application.\n",
        "- Open the Jupyter Notebook from your computer. This should open in a browser tab.\n",
        "- Download a personal copy of this notebook (\"File\" -> \"Download\" -> \"Download .ipynb\") which you would use for the practice session.\n",
        "- In the Jupyter tab in your browser, navigate the directory to the download folder and locate the downloaded file from the previous file.\n",
        "- Run the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9F-C8elBZWd"
      },
      "source": [
        "## Content\n",
        "- Artificial Intelligence (AI) and why it matters\n",
        "- Introduction to Machine Learning (ML)\n",
        "- Bayes Classifier\n",
        "- Naive Bayes\n",
        "- Linear and Quadratic Discriminant Analysis\n",
        "- Maximum Likelihood Estimation\n",
        "- Logistic Regression and Gradient Descent\n",
        "- Introduction to Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moBH88KiogdJ"
      },
      "source": [
        "## Artificial Intelligence (AI) and why it matters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJi2GGTh_zlS"
      },
      "source": [
        "> \"Intelligence demonstrated by machines, as opposed to natural intelligence displayed by animals including humans.\" - Wikipedia\n",
        "\n",
        "> \"Machines\" refer to: software systems, not necessarily robots\n",
        "\n",
        "> AI includes:\n",
        "- Learning\n",
        "- Reasoning\n",
        "- Knowledge representation\n",
        "- Planning\n",
        "- Perception (mostly computer vision (CV))\n",
        "- Natural language processing (NLP)\n",
        "\n",
        "> We do not currently have artificial **_general_** intelligence; Google's 2017 paper: One Model to Learn them All (https://arxiv.org/abs/1706.05137) is concerned only with learning across a set of CV and NLP tasks.\n",
        "\n",
        "> Current AI systems solve very specific learning and optimisation tasks:\n",
        "\n",
        "- Energy demand forecasting and optimal energy allocation\n",
        "- Fault detection in smart grids and optimised operation\n",
        "- Detection of wireless sensor network failure\n",
        "- Signal detection in massive MIMO (multiple input, multiple output) antenna systems\n",
        "- Predicting churn for telecom operators\n",
        "- Poultry health management with computer vision\n",
        "- Optimising mining operations\n",
        "- Sales forecasting and price optimisation\n",
        "- Diagnosing diseases such as cancer, diabetes, COVID-19/ medical assistive technology, e,g., in radiology/ robotic surgery\n",
        "- **Predicting level of engagement on a Twitter ad**\n",
        "\n",
        "... and there are even more mundane things:\n",
        "- article writing (https://www.theguardian.com/commentisfree/2020/sep/08/robot-wrote-this-article-gpt-3)\n",
        "\n",
        "> Whatever your interest, chances are AI (using data) could probably do a better job!\n",
        "\n",
        "> According to the World Economic Forum in 2020, AI will displace about 85 million jobs by 2025\n",
        "\n",
        "- Manufacturing\n",
        "- Engineering (traditional)\n",
        "- Medicine\n",
        "- Accounting\n",
        "- Taxi driving\n",
        "- Pharmaceuticals\n",
        "- Retail\n",
        "\n",
        "... but it would create 97 million new ones:\n",
        "- Software engineering\n",
        "- Science (including data science)\n",
        "- Product design\n",
        "- Project/team/product management\n",
        "- Writing (poetry, novels)\n",
        "\n",
        "> The part about AI concerned with learning, i.e., creating a system that learns from data on its own how to do any of the above specific tasks is \"Machine Learning\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m31NMI_ReJkG"
      },
      "source": [
        "## Introduction to Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezx3K4fw_mXz"
      },
      "source": [
        "> **Learning** from **data**\n",
        "\n",
        "> Data\n",
        " - Experimental data, survey data, Facebook feed, sales data, medical records, etc.\n",
        " - Forms: Tabular, text, images, etc.\n",
        "\n",
        "> Learning\n",
        " - Supervised learning\n",
        " - Unsupervised learning\n",
        " - Reinforcement learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMBaudY9og_s"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWBCmQj4omf0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbLe5FrYtzKs"
      },
      "source": [
        "#### Dataset 1 - California housing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsLzvTCt3c5Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4QFny_y93c5Z",
        "outputId": "f74790f5-a816-48b6-b4d7-88eedba0c945"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f5d9dff4-c419-46b2-8b43-bd4f337e5451\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20046</th>\n",
              "      <td>1.6812</td>\n",
              "      <td>25.0</td>\n",
              "      <td>4.192201</td>\n",
              "      <td>1.022284</td>\n",
              "      <td>1392.0</td>\n",
              "      <td>3.877437</td>\n",
              "      <td>36.06</td>\n",
              "      <td>-119.01</td>\n",
              "      <td>0.47700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3024</th>\n",
              "      <td>2.5313</td>\n",
              "      <td>30.0</td>\n",
              "      <td>5.039384</td>\n",
              "      <td>1.193493</td>\n",
              "      <td>1565.0</td>\n",
              "      <td>2.679795</td>\n",
              "      <td>35.14</td>\n",
              "      <td>-119.46</td>\n",
              "      <td>0.45800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15663</th>\n",
              "      <td>3.4801</td>\n",
              "      <td>52.0</td>\n",
              "      <td>3.977155</td>\n",
              "      <td>1.185877</td>\n",
              "      <td>1310.0</td>\n",
              "      <td>1.360332</td>\n",
              "      <td>37.80</td>\n",
              "      <td>-122.44</td>\n",
              "      <td>5.00001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20484</th>\n",
              "      <td>5.7376</td>\n",
              "      <td>17.0</td>\n",
              "      <td>6.163636</td>\n",
              "      <td>1.020202</td>\n",
              "      <td>1705.0</td>\n",
              "      <td>3.444444</td>\n",
              "      <td>34.28</td>\n",
              "      <td>-118.72</td>\n",
              "      <td>2.18600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9814</th>\n",
              "      <td>3.7250</td>\n",
              "      <td>34.0</td>\n",
              "      <td>5.492991</td>\n",
              "      <td>1.028037</td>\n",
              "      <td>1063.0</td>\n",
              "      <td>2.483645</td>\n",
              "      <td>36.62</td>\n",
              "      <td>-121.93</td>\n",
              "      <td>2.78000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5d9dff4-c419-46b2-8b43-bd4f337e5451')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5d9dff4-c419-46b2-8b43-bd4f337e5451 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5d9dff4-c419-46b2-8b43-bd4f337e5451');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       MedInc  HouseAge  AveRooms  ...  Latitude  Longitude  median_house_value\n",
              "20046  1.6812      25.0  4.192201  ...     36.06    -119.01             0.47700\n",
              "3024   2.5313      30.0  5.039384  ...     35.14    -119.46             0.45800\n",
              "15663  3.4801      52.0  3.977155  ...     37.80    -122.44             5.00001\n",
              "20484  5.7376      17.0  6.163636  ...     34.28    -118.72             2.18600\n",
              "9814   3.7250      34.0  5.492991  ...     36.62    -121.93             2.78000\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "california_object = fetch_california_housing(as_frame=True)\n",
        "df1 = california_object.data\n",
        "df1['median_house_value'] = california_object.target\n",
        "df1 = df1.sample(frac=1, random_state=42)\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK9a7kZc1a5T"
      },
      "source": [
        "> Troubleshooting:\n",
        "If the above cell fails to run, upgrade sklearn by running the following in a code cell:\n",
        "\n",
        "`!pip install -U scikit-learn`\n",
        "\n",
        "- Then, delete or comment out the cell you create, and restart the runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k5HpAqDpr5g",
        "outputId": "b95ade55-e63f-48e8-a6f0-24c392e4e5ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20640, 9)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi2te_fa_WU1"
      },
      "source": [
        "> Example task: predict `median_house_value`\n",
        "- Regression (real, continuous output)\n",
        "\n",
        "> Target, or label, or dependent variable: `median_house_value`\n",
        "\n",
        "> Features, or input variables, or dependent variables:\n",
        "`'MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude'`\n",
        "\n",
        "\n",
        "> Number of rows $n = 20640$\n",
        "\n",
        "> Number of features $d = 8$ (dimensionality)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LUwQCdwYhk5"
      },
      "source": [
        "#### Dataset 2 - Breast Cancer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGwt6Esl0owr"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "QKoxFDva0rer",
        "outputId": "0dae7ce6-dbb7-4082-99b5-4492782f80dc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8b308efb-a2d2-43b9-bf00-811ced1c16f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>malignant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>12.47</td>\n",
              "      <td>18.60</td>\n",
              "      <td>81.09</td>\n",
              "      <td>481.9</td>\n",
              "      <td>0.09965</td>\n",
              "      <td>0.1058</td>\n",
              "      <td>0.08005</td>\n",
              "      <td>0.03821</td>\n",
              "      <td>0.1925</td>\n",
              "      <td>0.06373</td>\n",
              "      <td>0.3961</td>\n",
              "      <td>1.0440</td>\n",
              "      <td>2.497</td>\n",
              "      <td>30.29</td>\n",
              "      <td>0.006953</td>\n",
              "      <td>0.01911</td>\n",
              "      <td>0.02701</td>\n",
              "      <td>0.01037</td>\n",
              "      <td>0.01782</td>\n",
              "      <td>0.003586</td>\n",
              "      <td>14.97</td>\n",
              "      <td>24.64</td>\n",
              "      <td>96.05</td>\n",
              "      <td>677.9</td>\n",
              "      <td>0.1426</td>\n",
              "      <td>0.2378</td>\n",
              "      <td>0.2671</td>\n",
              "      <td>0.10150</td>\n",
              "      <td>0.3014</td>\n",
              "      <td>0.08750</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>18.94</td>\n",
              "      <td>21.31</td>\n",
              "      <td>123.60</td>\n",
              "      <td>1130.0</td>\n",
              "      <td>0.09009</td>\n",
              "      <td>0.1029</td>\n",
              "      <td>0.10800</td>\n",
              "      <td>0.07951</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.05461</td>\n",
              "      <td>0.7888</td>\n",
              "      <td>0.7975</td>\n",
              "      <td>5.486</td>\n",
              "      <td>96.05</td>\n",
              "      <td>0.004444</td>\n",
              "      <td>0.01652</td>\n",
              "      <td>0.02269</td>\n",
              "      <td>0.01370</td>\n",
              "      <td>0.01386</td>\n",
              "      <td>0.001698</td>\n",
              "      <td>24.86</td>\n",
              "      <td>26.58</td>\n",
              "      <td>165.90</td>\n",
              "      <td>1866.0</td>\n",
              "      <td>0.1193</td>\n",
              "      <td>0.2336</td>\n",
              "      <td>0.2687</td>\n",
              "      <td>0.17890</td>\n",
              "      <td>0.2551</td>\n",
              "      <td>0.06589</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>15.46</td>\n",
              "      <td>19.48</td>\n",
              "      <td>101.70</td>\n",
              "      <td>748.9</td>\n",
              "      <td>0.10920</td>\n",
              "      <td>0.1223</td>\n",
              "      <td>0.14660</td>\n",
              "      <td>0.08087</td>\n",
              "      <td>0.1931</td>\n",
              "      <td>0.05796</td>\n",
              "      <td>0.4743</td>\n",
              "      <td>0.7859</td>\n",
              "      <td>3.094</td>\n",
              "      <td>48.31</td>\n",
              "      <td>0.006240</td>\n",
              "      <td>0.01484</td>\n",
              "      <td>0.02813</td>\n",
              "      <td>0.01093</td>\n",
              "      <td>0.01397</td>\n",
              "      <td>0.002461</td>\n",
              "      <td>19.26</td>\n",
              "      <td>26.00</td>\n",
              "      <td>124.90</td>\n",
              "      <td>1156.0</td>\n",
              "      <td>0.1546</td>\n",
              "      <td>0.2394</td>\n",
              "      <td>0.3791</td>\n",
              "      <td>0.15140</td>\n",
              "      <td>0.2837</td>\n",
              "      <td>0.08019</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>12.40</td>\n",
              "      <td>17.68</td>\n",
              "      <td>81.47</td>\n",
              "      <td>467.8</td>\n",
              "      <td>0.10540</td>\n",
              "      <td>0.1316</td>\n",
              "      <td>0.07741</td>\n",
              "      <td>0.02799</td>\n",
              "      <td>0.1811</td>\n",
              "      <td>0.07102</td>\n",
              "      <td>0.1767</td>\n",
              "      <td>1.4600</td>\n",
              "      <td>2.204</td>\n",
              "      <td>15.43</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.03295</td>\n",
              "      <td>0.04861</td>\n",
              "      <td>0.01167</td>\n",
              "      <td>0.02187</td>\n",
              "      <td>0.006005</td>\n",
              "      <td>12.88</td>\n",
              "      <td>22.91</td>\n",
              "      <td>89.61</td>\n",
              "      <td>515.8</td>\n",
              "      <td>0.1450</td>\n",
              "      <td>0.2629</td>\n",
              "      <td>0.2403</td>\n",
              "      <td>0.07370</td>\n",
              "      <td>0.2556</td>\n",
              "      <td>0.09359</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>11.54</td>\n",
              "      <td>14.44</td>\n",
              "      <td>74.65</td>\n",
              "      <td>402.9</td>\n",
              "      <td>0.09984</td>\n",
              "      <td>0.1120</td>\n",
              "      <td>0.06737</td>\n",
              "      <td>0.02594</td>\n",
              "      <td>0.1818</td>\n",
              "      <td>0.06782</td>\n",
              "      <td>0.2784</td>\n",
              "      <td>1.7680</td>\n",
              "      <td>1.628</td>\n",
              "      <td>20.86</td>\n",
              "      <td>0.012150</td>\n",
              "      <td>0.04112</td>\n",
              "      <td>0.05553</td>\n",
              "      <td>0.01494</td>\n",
              "      <td>0.01840</td>\n",
              "      <td>0.005512</td>\n",
              "      <td>12.26</td>\n",
              "      <td>19.68</td>\n",
              "      <td>78.78</td>\n",
              "      <td>457.8</td>\n",
              "      <td>0.1345</td>\n",
              "      <td>0.2118</td>\n",
              "      <td>0.1797</td>\n",
              "      <td>0.06918</td>\n",
              "      <td>0.2329</td>\n",
              "      <td>0.08134</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b308efb-a2d2-43b9-bf00-811ced1c16f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b308efb-a2d2-43b9-bf00-811ced1c16f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b308efb-a2d2-43b9-bf00-811ced1c16f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst fractal dimension  malignant\n",
              "204        12.47         18.60  ...                  0.08750          1\n",
              "70         18.94         21.31  ...                  0.06589          0\n",
              "131        15.46         19.48  ...                  0.08019          0\n",
              "431        12.40         17.68  ...                  0.09359          1\n",
              "540        11.54         14.44  ...                  0.08134          1\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "breast_cancer_object = load_breast_cancer(as_frame=True)\n",
        "df2 = breast_cancer_object.data\n",
        "df2['malignant'] = breast_cancer_object.target\n",
        "df2 = df2.sample(frac=1, random_state=42)\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z55fpvg5aPRZ",
        "outputId": "f3f6b8c5-c06a-4c6a-c029-e2fc0d832592"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(569, 31)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSVpyKDmJJy7",
        "outputId": "edc0f67a-9e58-439f-9618-a18c15cea825"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2['malignant'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFJnAIPmMQQt"
      },
      "outputs": [],
      "source": [
        "class_names_df2 = {0: 'benign', 1: 'malignant'} #dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9ONzEvIF2tZ"
      },
      "source": [
        "> Example task: predict whether or not a tumour is `malignant`\n",
        "- Classification (categorical output)\n",
        "\n",
        "> Target, or label, or dependent variable: `species`\n",
        "\n",
        "> Features, or input variables, or dependent variables:\n",
        "`'mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
        "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
        "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
        "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
        "       'smoothness error', 'compactness error', 'concavity error',\n",
        "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
        "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
        "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
        "       'worst concave points', 'worst symmetry', 'worst fractal dimension'`\n",
        "\n",
        "\n",
        "> Number of rows $n = 569$\n",
        "\n",
        "> Number of features $d = 30$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-9ytA3-ZeBo"
      },
      "source": [
        "#### Dataset 3 - Iris flower data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JxqIwK22M7A"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ramwFj4Epl8A",
        "outputId": "935436ff-6f45-4abc-d718-cab097906984"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-80a59545-78c3-499d-b88a-e51be2a26940\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>6.1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.7</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>7.7</td>\n",
              "      <td>2.6</td>\n",
              "      <td>6.9</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>6.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>6.8</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80a59545-78c3-499d-b88a-e51be2a26940')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80a59545-78c3-499d-b88a-e51be2a26940 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80a59545-78c3-499d-b88a-e51be2a26940');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     sepal length (cm)  sepal width (cm)  ...  petal width (cm)  species\n",
              "73                 6.1               2.8  ...               1.2        1\n",
              "18                 5.7               3.8  ...               0.3        0\n",
              "118                7.7               2.6  ...               2.3        2\n",
              "78                 6.0               2.9  ...               1.5        1\n",
              "76                 6.8               2.8  ...               1.4        1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iris_object = load_iris(as_frame=True)\n",
        "df3 = iris_object.data\n",
        "df3['species'] = iris_object.target\n",
        "df3 = df3.sample(frac=1, random_state=42)\n",
        "df3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvnUzi9daIwJ",
        "outputId": "41578aa1-aeef-488e-fdd0-9ec8e2391a14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(150, 5)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DqY_0F2GfH3",
        "outputId": "de0cb725-74d5-4db5-a4b2-3c44195777f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 2])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3['species'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSqAP1jaMcB6"
      },
      "outputs": [],
      "source": [
        "class_names_df3 = {0: 'Iris setosa', 1: 'Iris versicolor', 2: 'Iris virginica'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-Ak2bp_DSX5"
      },
      "source": [
        "> Example task: predict `species`\n",
        "- Classification (categorical output)\n",
        "\n",
        "> Target, or label, or dependent variable: `species`\n",
        "\n",
        "> Features, or input variables, or dependent variables:\n",
        "`'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
        "       'petal width (cm)'`\n",
        "\n",
        "\n",
        "> Number of rows $n = 150$\n",
        "\n",
        "> Number of features $d = 4$\n",
        "\n",
        "> Set of features in one row: vector $\\textbf{x}$\n",
        "\n",
        "- $\\textbf{x}_0 = [6.1,\t2.8,\t4.7,\t1.2]^\\top$\n",
        "\n",
        "- $\\textbf{x}_1 = [5.7,\t3.8,\t1.7,\t0.3]^\\top$\n",
        "\n",
        "- $\\vdots$\n",
        "\n",
        "- $\\textbf{x}_i = [6.8,\t2.8,\t4.8,\t1.4\t]^\\top$\n",
        "\n",
        "> $i$ indexes the row in the data, where $i \\in \\{0, 1, ..., n-1\\}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLg2tFMWe-Xk"
      },
      "source": [
        "### Supervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACLJVpsOfCxe"
      },
      "source": [
        "- We have input and output information\n",
        " - Input: $\\textbf{x}$\n",
        " - Output: $y$, aka target, label\n",
        "\n",
        "- Relationship between $\\textbf{x}$ and $y$ unknown (or too complicated to put down)\n",
        "\n",
        "- There is data\n",
        "\n",
        "- There is an imaginary supervisor, providing the correct labels $y$ (ideally**) for every input $\\textbf{x}$.\n",
        "\n",
        "> **Labels are often noisy and can sometimes be adversarial, too.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZM2sM1SheC8"
      },
      "source": [
        "#### Mapping: a junior high school example\n",
        "---\n",
        "- Mapping 1:\n",
        "\n",
        "\\begin{align}\n",
        "&x:\\quad 0 \\quad 1 \\quad 2 \\quad 3 \\quad 4 \\quad 5 \\quad 6\\\\\n",
        "&y:\\quad 9 \\quad 4 \\quad 1 \\quad 0 \\quad 1 \\quad 4 \\quad 9\n",
        "\\end{align}\n",
        "\n",
        "- Rule?\n",
        "---\n",
        "- Mapping 2:\n",
        "\n",
        "\\begin{align}\n",
        "&x:\\quad 0.10 \\quad 0.20 \\quad 0.30 \\quad 0.40 \\quad 0.50 \\quad 0.60 \\quad 0.70\\\\\n",
        "&y:\\quad 0.33 \\quad 0.46 \\quad 0.52 \\quad 0.53 \\quad 0.50 \\quad 0.44 \\quad 0.36\n",
        "\\end{align}\n",
        "\n",
        "- Rule?\n",
        "---\n",
        "\n",
        "- Mapping 3:\n",
        "\n",
        "\\begin{align}\n",
        "& x_1:\\quad 3 \\quad -1 \\quad -2 \\quad +2 \\quad -2 \\quad -6\\\\\n",
        "& x_2:\\quad 6 \\quad -2  \\quad -5 \\quad -4 \\quad -1 \\quad +3\\\\\n",
        "& y :\\quad -1 \\quad +1 \\quad +1 \\quad +1 \\quad -1 \\quad -1\n",
        "\\end{align}\n",
        "\n",
        "- Rule?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-kk_ItrjIFw"
      },
      "source": [
        "#### Mapping: breast cancer data example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "hCdxS-4mrTov",
        "outputId": "20f1fd87-272a-404d-ad02-19830778cb0e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3dc8eb4a-bcc4-40a0-a605-08b05d131fc0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>malignant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>12.47</td>\n",
              "      <td>18.60</td>\n",
              "      <td>81.09</td>\n",
              "      <td>481.9</td>\n",
              "      <td>0.09965</td>\n",
              "      <td>0.1058</td>\n",
              "      <td>0.08005</td>\n",
              "      <td>0.03821</td>\n",
              "      <td>0.1925</td>\n",
              "      <td>0.06373</td>\n",
              "      <td>0.3961</td>\n",
              "      <td>1.0440</td>\n",
              "      <td>2.497</td>\n",
              "      <td>30.29</td>\n",
              "      <td>0.006953</td>\n",
              "      <td>0.01911</td>\n",
              "      <td>0.02701</td>\n",
              "      <td>0.01037</td>\n",
              "      <td>0.01782</td>\n",
              "      <td>0.003586</td>\n",
              "      <td>14.97</td>\n",
              "      <td>24.64</td>\n",
              "      <td>96.05</td>\n",
              "      <td>677.9</td>\n",
              "      <td>0.1426</td>\n",
              "      <td>0.2378</td>\n",
              "      <td>0.2671</td>\n",
              "      <td>0.10150</td>\n",
              "      <td>0.3014</td>\n",
              "      <td>0.08750</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>18.94</td>\n",
              "      <td>21.31</td>\n",
              "      <td>123.60</td>\n",
              "      <td>1130.0</td>\n",
              "      <td>0.09009</td>\n",
              "      <td>0.1029</td>\n",
              "      <td>0.10800</td>\n",
              "      <td>0.07951</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.05461</td>\n",
              "      <td>0.7888</td>\n",
              "      <td>0.7975</td>\n",
              "      <td>5.486</td>\n",
              "      <td>96.05</td>\n",
              "      <td>0.004444</td>\n",
              "      <td>0.01652</td>\n",
              "      <td>0.02269</td>\n",
              "      <td>0.01370</td>\n",
              "      <td>0.01386</td>\n",
              "      <td>0.001698</td>\n",
              "      <td>24.86</td>\n",
              "      <td>26.58</td>\n",
              "      <td>165.90</td>\n",
              "      <td>1866.0</td>\n",
              "      <td>0.1193</td>\n",
              "      <td>0.2336</td>\n",
              "      <td>0.2687</td>\n",
              "      <td>0.17890</td>\n",
              "      <td>0.2551</td>\n",
              "      <td>0.06589</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>15.46</td>\n",
              "      <td>19.48</td>\n",
              "      <td>101.70</td>\n",
              "      <td>748.9</td>\n",
              "      <td>0.10920</td>\n",
              "      <td>0.1223</td>\n",
              "      <td>0.14660</td>\n",
              "      <td>0.08087</td>\n",
              "      <td>0.1931</td>\n",
              "      <td>0.05796</td>\n",
              "      <td>0.4743</td>\n",
              "      <td>0.7859</td>\n",
              "      <td>3.094</td>\n",
              "      <td>48.31</td>\n",
              "      <td>0.006240</td>\n",
              "      <td>0.01484</td>\n",
              "      <td>0.02813</td>\n",
              "      <td>0.01093</td>\n",
              "      <td>0.01397</td>\n",
              "      <td>0.002461</td>\n",
              "      <td>19.26</td>\n",
              "      <td>26.00</td>\n",
              "      <td>124.90</td>\n",
              "      <td>1156.0</td>\n",
              "      <td>0.1546</td>\n",
              "      <td>0.2394</td>\n",
              "      <td>0.3791</td>\n",
              "      <td>0.15140</td>\n",
              "      <td>0.2837</td>\n",
              "      <td>0.08019</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>12.40</td>\n",
              "      <td>17.68</td>\n",
              "      <td>81.47</td>\n",
              "      <td>467.8</td>\n",
              "      <td>0.10540</td>\n",
              "      <td>0.1316</td>\n",
              "      <td>0.07741</td>\n",
              "      <td>0.02799</td>\n",
              "      <td>0.1811</td>\n",
              "      <td>0.07102</td>\n",
              "      <td>0.1767</td>\n",
              "      <td>1.4600</td>\n",
              "      <td>2.204</td>\n",
              "      <td>15.43</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.03295</td>\n",
              "      <td>0.04861</td>\n",
              "      <td>0.01167</td>\n",
              "      <td>0.02187</td>\n",
              "      <td>0.006005</td>\n",
              "      <td>12.88</td>\n",
              "      <td>22.91</td>\n",
              "      <td>89.61</td>\n",
              "      <td>515.8</td>\n",
              "      <td>0.1450</td>\n",
              "      <td>0.2629</td>\n",
              "      <td>0.2403</td>\n",
              "      <td>0.07370</td>\n",
              "      <td>0.2556</td>\n",
              "      <td>0.09359</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>11.54</td>\n",
              "      <td>14.44</td>\n",
              "      <td>74.65</td>\n",
              "      <td>402.9</td>\n",
              "      <td>0.09984</td>\n",
              "      <td>0.1120</td>\n",
              "      <td>0.06737</td>\n",
              "      <td>0.02594</td>\n",
              "      <td>0.1818</td>\n",
              "      <td>0.06782</td>\n",
              "      <td>0.2784</td>\n",
              "      <td>1.7680</td>\n",
              "      <td>1.628</td>\n",
              "      <td>20.86</td>\n",
              "      <td>0.012150</td>\n",
              "      <td>0.04112</td>\n",
              "      <td>0.05553</td>\n",
              "      <td>0.01494</td>\n",
              "      <td>0.01840</td>\n",
              "      <td>0.005512</td>\n",
              "      <td>12.26</td>\n",
              "      <td>19.68</td>\n",
              "      <td>78.78</td>\n",
              "      <td>457.8</td>\n",
              "      <td>0.1345</td>\n",
              "      <td>0.2118</td>\n",
              "      <td>0.1797</td>\n",
              "      <td>0.06918</td>\n",
              "      <td>0.2329</td>\n",
              "      <td>0.08134</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3dc8eb4a-bcc4-40a0-a605-08b05d131fc0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3dc8eb4a-bcc4-40a0-a605-08b05d131fc0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3dc8eb4a-bcc4-40a0-a605-08b05d131fc0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst fractal dimension  malignant\n",
              "204        12.47         18.60  ...                  0.08750          1\n",
              "70         18.94         21.31  ...                  0.06589          0\n",
              "131        15.46         19.48  ...                  0.08019          0\n",
              "431        12.40         17.68  ...                  0.09359          1\n",
              "540        11.54         14.44  ...                  0.08134          1\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1M6a_enxiPg"
      },
      "source": [
        "> Histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK5s_VBXr5aF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "9HUqb13EwauE",
        "outputId": "5bb0c643-86fa-40f4-b92e-630f4e06a35d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(df2[df2['malignant']==0]['mean radius'], color='b') #plotting the mean radius for the benign instances; color code 'b' = 'blue'\n",
        "plt.hist(df2[df2['malignant']==1]['mean radius'], color='r') #plotting the mean radius for the malignant instances; color code 'r' = 'red'\n",
        "plt.grid(True) #adding a grid on the plot\n",
        "plt.xlabel('mean radius') #adding a label on the x-axis\n",
        "plt.ylabel('count or frequency') #adding a label on the y-axis\n",
        "plt.legend(['Benign (0)', 'Malignant (1)']) #adding a legend to the plot\n",
        "plt.show() #displaying plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOdTVzLDx7DV"
      },
      "source": [
        "> Rule:\n",
        "```\n",
        "if 'mean radius' > 15: \n",
        "  then y = 'benign'\n",
        "else:\n",
        "  y = 'malignant'\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkNFNNx75FHO"
      },
      "source": [
        "> Decision rule:\n",
        "\n",
        "\\begin{equation}\n",
        "h(\\textbf{x}) \\mathop{\\lessgtr}_{y=0}^{y=1} \\tau\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI--BLJ4pDKr"
      },
      "source": [
        "> Extra features might help with the decision rule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "-zO6gm8Fml89",
        "outputId": "c7c4ed9a-05a9-4d02-9864-f519564a70da"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(df2[df2['malignant']==0]['mean radius'], df2[df2['malignant']==0]['mean concavity'], 'bo') \n",
        "#plotting the mean radius and mean texture for the benign instances; color code 'b': 'blue'; marker code 'o': circular points\n",
        "plt.plot(df2[df2['malignant']==1]['mean radius'], df2[df2['malignant']==1]['mean concavity'], 'ro') \n",
        "#plotting the mean radius and mean texture for the malignant instances; color code 'r': 'red'; marker code 'o': circular points\n",
        "plt.grid(True) #adding a grid on the plot\n",
        "plt.xlabel('mean radius') #adding a label on the x-axis\n",
        "plt.ylabel('mean concavity') #adding a label on the y-axis\n",
        "plt.legend(['Benign (0)', 'Malignant (1)']) #adding a legend to the plot\n",
        "plt.show() #displaying plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGwiGcE1pvXU"
      },
      "source": [
        "> Decision boundary, aka hyperplane\n",
        "- E.g., defined by boundary passing through: `mean radius = 15, mean concavity = 0.1`\n",
        "\n",
        "> Rule:\n",
        "```\n",
        "if 'mean radius' > 15 or mean concavity > 0.1: \n",
        "  then y = 'benign'\n",
        "else:\n",
        "  y = 'malignant'\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urBBUEbkVH2C"
      },
      "source": [
        "#### Generalisation: How do we know we have the correct rule?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4KpWYnwVzbZ"
      },
      "source": [
        "- Mapping 4:\n",
        "\n",
        "\\begin{align}\n",
        "&\\textbf{x}:\\quad -1 \\quad 0 \\quad +1 \\quad +2 \\quad +3\\\\\n",
        "&y:\\quad +1 \\quad 0 \\quad +1\n",
        "\\end{align}\n",
        "\n",
        "- Rule?\n",
        "\n",
        "---\n",
        "\n",
        "- Mapping 5:\n",
        "\\begin{align}\n",
        "&\\textbf{x}:\\quad -1 \\quad 0 \\quad +1 \\quad +2 \\quad +3\\\\\n",
        "&y:\\quad +1 \\quad 0 \\quad +1 \\quad +2\n",
        "\\end{align}\n",
        "\n",
        "- Rule?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PCZVMDIYH-S"
      },
      "source": [
        "> Training - validation split\n",
        "- We split our data into two (or three):\n",
        "  - We train the model on one set (training set)\n",
        "  - We validate/test the model on the other sets (validation/test sets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSgAe4eWVzX2"
      },
      "source": [
        "#### Generalisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VvVHgBMVzSr"
      },
      "source": [
        "> There is some true function $f: \\mathcal{X} ⟼ \\mathcal{y}$\n",
        "\n",
        "> Come up with a hypothesis function $h$ from the training set\n",
        "- where $h \\in \\mathcal{H}$, the set of all hypothesis functions\n",
        "\n",
        "> On the validation set:\n",
        "\\begin{equation}\n",
        "h(\\textbf{x}_{val}) \\approx f(\\textbf{x}_{val})\n",
        "\\end{equation}\n",
        "\n",
        "> Probably Approximately Correct (PAC)\n",
        "\\begin{equation}\n",
        "P(| h(\\textbf{x}_{val}) - f(\\textbf{x}_{val}) | < \\epsilon) > p\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6mTTgEoqZLw"
      },
      "source": [
        "## Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "duHms_TS2RwI",
        "outputId": "e29e3f06-7edc-4d75-ced3-7db6765387d0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e5fef412-f5d3-46bb-baf7-95c9c3217485\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>malignant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>12.47</td>\n",
              "      <td>18.60</td>\n",
              "      <td>81.09</td>\n",
              "      <td>481.9</td>\n",
              "      <td>0.09965</td>\n",
              "      <td>0.1058</td>\n",
              "      <td>0.08005</td>\n",
              "      <td>0.03821</td>\n",
              "      <td>0.1925</td>\n",
              "      <td>0.06373</td>\n",
              "      <td>0.3961</td>\n",
              "      <td>1.0440</td>\n",
              "      <td>2.497</td>\n",
              "      <td>30.29</td>\n",
              "      <td>0.006953</td>\n",
              "      <td>0.01911</td>\n",
              "      <td>0.02701</td>\n",
              "      <td>0.01037</td>\n",
              "      <td>0.01782</td>\n",
              "      <td>0.003586</td>\n",
              "      <td>14.97</td>\n",
              "      <td>24.64</td>\n",
              "      <td>96.05</td>\n",
              "      <td>677.9</td>\n",
              "      <td>0.1426</td>\n",
              "      <td>0.2378</td>\n",
              "      <td>0.2671</td>\n",
              "      <td>0.10150</td>\n",
              "      <td>0.3014</td>\n",
              "      <td>0.08750</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>18.94</td>\n",
              "      <td>21.31</td>\n",
              "      <td>123.60</td>\n",
              "      <td>1130.0</td>\n",
              "      <td>0.09009</td>\n",
              "      <td>0.1029</td>\n",
              "      <td>0.10800</td>\n",
              "      <td>0.07951</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.05461</td>\n",
              "      <td>0.7888</td>\n",
              "      <td>0.7975</td>\n",
              "      <td>5.486</td>\n",
              "      <td>96.05</td>\n",
              "      <td>0.004444</td>\n",
              "      <td>0.01652</td>\n",
              "      <td>0.02269</td>\n",
              "      <td>0.01370</td>\n",
              "      <td>0.01386</td>\n",
              "      <td>0.001698</td>\n",
              "      <td>24.86</td>\n",
              "      <td>26.58</td>\n",
              "      <td>165.90</td>\n",
              "      <td>1866.0</td>\n",
              "      <td>0.1193</td>\n",
              "      <td>0.2336</td>\n",
              "      <td>0.2687</td>\n",
              "      <td>0.17890</td>\n",
              "      <td>0.2551</td>\n",
              "      <td>0.06589</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>15.46</td>\n",
              "      <td>19.48</td>\n",
              "      <td>101.70</td>\n",
              "      <td>748.9</td>\n",
              "      <td>0.10920</td>\n",
              "      <td>0.1223</td>\n",
              "      <td>0.14660</td>\n",
              "      <td>0.08087</td>\n",
              "      <td>0.1931</td>\n",
              "      <td>0.05796</td>\n",
              "      <td>0.4743</td>\n",
              "      <td>0.7859</td>\n",
              "      <td>3.094</td>\n",
              "      <td>48.31</td>\n",
              "      <td>0.006240</td>\n",
              "      <td>0.01484</td>\n",
              "      <td>0.02813</td>\n",
              "      <td>0.01093</td>\n",
              "      <td>0.01397</td>\n",
              "      <td>0.002461</td>\n",
              "      <td>19.26</td>\n",
              "      <td>26.00</td>\n",
              "      <td>124.90</td>\n",
              "      <td>1156.0</td>\n",
              "      <td>0.1546</td>\n",
              "      <td>0.2394</td>\n",
              "      <td>0.3791</td>\n",
              "      <td>0.15140</td>\n",
              "      <td>0.2837</td>\n",
              "      <td>0.08019</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>12.40</td>\n",
              "      <td>17.68</td>\n",
              "      <td>81.47</td>\n",
              "      <td>467.8</td>\n",
              "      <td>0.10540</td>\n",
              "      <td>0.1316</td>\n",
              "      <td>0.07741</td>\n",
              "      <td>0.02799</td>\n",
              "      <td>0.1811</td>\n",
              "      <td>0.07102</td>\n",
              "      <td>0.1767</td>\n",
              "      <td>1.4600</td>\n",
              "      <td>2.204</td>\n",
              "      <td>15.43</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.03295</td>\n",
              "      <td>0.04861</td>\n",
              "      <td>0.01167</td>\n",
              "      <td>0.02187</td>\n",
              "      <td>0.006005</td>\n",
              "      <td>12.88</td>\n",
              "      <td>22.91</td>\n",
              "      <td>89.61</td>\n",
              "      <td>515.8</td>\n",
              "      <td>0.1450</td>\n",
              "      <td>0.2629</td>\n",
              "      <td>0.2403</td>\n",
              "      <td>0.07370</td>\n",
              "      <td>0.2556</td>\n",
              "      <td>0.09359</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>11.54</td>\n",
              "      <td>14.44</td>\n",
              "      <td>74.65</td>\n",
              "      <td>402.9</td>\n",
              "      <td>0.09984</td>\n",
              "      <td>0.1120</td>\n",
              "      <td>0.06737</td>\n",
              "      <td>0.02594</td>\n",
              "      <td>0.1818</td>\n",
              "      <td>0.06782</td>\n",
              "      <td>0.2784</td>\n",
              "      <td>1.7680</td>\n",
              "      <td>1.628</td>\n",
              "      <td>20.86</td>\n",
              "      <td>0.012150</td>\n",
              "      <td>0.04112</td>\n",
              "      <td>0.05553</td>\n",
              "      <td>0.01494</td>\n",
              "      <td>0.01840</td>\n",
              "      <td>0.005512</td>\n",
              "      <td>12.26</td>\n",
              "      <td>19.68</td>\n",
              "      <td>78.78</td>\n",
              "      <td>457.8</td>\n",
              "      <td>0.1345</td>\n",
              "      <td>0.2118</td>\n",
              "      <td>0.1797</td>\n",
              "      <td>0.06918</td>\n",
              "      <td>0.2329</td>\n",
              "      <td>0.08134</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5fef412-f5d3-46bb-baf7-95c9c3217485')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e5fef412-f5d3-46bb-baf7-95c9c3217485 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e5fef412-f5d3-46bb-baf7-95c9c3217485');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst fractal dimension  malignant\n",
              "204        12.47         18.60  ...                  0.08750          1\n",
              "70         18.94         21.31  ...                  0.06589          0\n",
              "131        15.46         19.48  ...                  0.08019          0\n",
              "431        12.40         17.68  ...                  0.09359          1\n",
              "540        11.54         14.44  ...                  0.08134          1\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DvEi5HM2xcU"
      },
      "source": [
        "> Task: predict whether or not a tumour is `malignant`\n",
        "- Classification (categorical output)\n",
        "\n",
        "- Target $y \\in \\{0, 1\\}$\n",
        "- Feature vector $\\textbf{x}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjCDDRzP25gj",
        "outputId": "d08b1e11-350f-4533-fd37-a9769717297d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('benign', 'malignant')"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_names_df2[0], class_names_df2[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbRZFLimqgCS"
      },
      "source": [
        "> $p(y=1| \\textbf{x})$ vs $p(y=0| \\textbf{x})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpIa8D37rWhN"
      },
      "source": [
        "> Notation:\n",
        "\n",
        "\\begin{equation}\n",
        "\\max_k p(y=k | \\textbf{x}), \\forall k \\in\\{0,1\\}\n",
        "\\end{equation}\n",
        "\n",
        "> Posterior probability: $p(y=k | \\textbf{x})$\n",
        "- *Maximum a posteriori* (MAP) decision rule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cisoBZTyiAUu"
      },
      "source": [
        "> Suppose we had only one feature:\n",
        "- $\\textbf{x} = x$ (`mean radius`)\n",
        "- $p(y=1| x=12.47)$ vs $p(y=0| x=12.47)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XejrSdwKtGn0"
      },
      "source": [
        "### Bayes theorem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5ot2n26tdar"
      },
      "source": [
        "\\begin{equation}\n",
        "p(A|B) = \\frac{p(B|A)p(A)}{p(B)} = \\frac{p(B|A)p(A)}{\\sum_A p(B|A)p(A)}\n",
        "\\end{equation}\n",
        "\n",
        "It follows that:\n",
        "\n",
        "\\begin{equation}\n",
        "p(y=0|x) = \\frac{p(x|y=0)p(y=0)}{p(x)}\n",
        "\\end{equation}\n",
        "\n",
        "Similarly,\n",
        "\\begin{equation}\n",
        "p(y=1|x) = \\frac{p(x|y=1)p(y=1)}{p(x)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHuVHJP7geWi"
      },
      "source": [
        "> Likelihood:\n",
        "- $p(x| y=0)$\n",
        "- $p(x| y=1)$\n",
        "\n",
        "> Prior:\n",
        "- $p(y=0)$\n",
        "- $p(y=1)$\n",
        "\n",
        "> Evidence:\n",
        "- $x$\n",
        "\n",
        "> Who cares about $p(x)$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbuBBY4BkNm5"
      },
      "source": [
        "> Rather than asking: \n",
        "- $p(y=1 | x= 12.47)$\n",
        "- $p(y=0 | x= 12.47)$\n",
        "\n",
        "> we have instead:\n",
        "- $p(x=12.47 | y=1)$\n",
        "- $p(x=12.47 | y=0)$\n",
        "- Consideration for the priors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS2Oe4qZR7zH"
      },
      "source": [
        "> Assumption: Gaussian (or normal) distribution\n",
        "- Normal distributions are normal (https://aidanlyon.com/normal_distributions.pdf)\n",
        "- A consequence of the central limit theorem (CLT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpHOy6cQtRo7"
      },
      "source": [
        "> Demonstration of the CLT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxwShGCKJK98"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJJDJK4JtWm7",
        "outputId": "3f333a57-a925-42d1-be73-0e8ba8bd55c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.62596089, 0.513348  , 0.70856169, 0.82397926, 0.28200715,\n",
              "       0.15827102, 0.5061127 , 0.47615838, 0.63080133, 0.81870926,\n",
              "       0.00198225, 0.17629704, 0.33119377, 0.58574153, 0.08705523,\n",
              "       0.46390955, 0.95948879, 0.3079219 , 0.8199789 , 0.74594679,\n",
              "       0.89708528, 0.33958802, 0.66883502, 0.935478  , 0.81388239,\n",
              "       0.07025574, 0.8026309 , 0.7457868 , 0.7420454 , 0.21083781,\n",
              "       0.57024783, 0.11763193, 0.52252919, 0.44380019, 0.34089948,\n",
              "       0.02873367, 0.32628001, 0.33805596, 0.87993638, 0.2660367 ,\n",
              "       0.56612513, 0.65048603, 0.61692209, 0.35077552, 0.85507081,\n",
              "       0.18500453, 0.21361331, 0.99964697, 0.41060996, 0.86169292,\n",
              "       0.72148194, 0.25171971, 0.60666065, 0.82660647, 0.48469603,\n",
              "       0.13847435, 0.91031097, 0.53251077, 0.89083947, 0.46698517,\n",
              "       0.29315524, 0.09804239, 0.01250881, 0.32248092, 0.01228766,\n",
              "       0.52495127, 0.90105035, 0.68628965, 0.72032499, 0.15940586,\n",
              "       0.84468467, 0.8528543 , 0.85322218, 0.13622987, 0.53544769,\n",
              "       0.36606462, 0.54950109, 0.38284941, 0.93483828, 0.66183465,\n",
              "       0.45345025, 0.14413267, 0.65193425, 0.44783403, 0.59485446,\n",
              "       0.38551454, 0.48190866, 0.60720728, 0.97669186, 0.42665267,\n",
              "       0.98823654, 0.75345046, 0.71765201, 0.57149054, 0.01166344,\n",
              "       0.20354256, 0.38384874, 0.65954529, 0.26309575, 0.3836706 ])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get random numbers\n",
        "\n",
        "population = np.random.uniform(size=100)\n",
        "#population = [0.2, 7.9, 4, 18, 6000, 0.14, -17, 0, 16, 69, 419, -0.5, 85, -11, 0.125, 14]\n",
        "population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "iu_hmRKZSjz_",
        "outputId": "66d53609-20ff-4dba-ac09-2955572a6dc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 8.,  8.,  8., 13., 10., 12., 11.,  8., 14.,  8.]),\n",
              " array([0.00198225, 0.10174872, 0.2015152 , 0.30128167, 0.40104814,\n",
              "        0.50081461, 0.60058108, 0.70034756, 0.80011403, 0.8998805 ,\n",
              "        0.99964697]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(population)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0SYZxzztaZ8"
      },
      "outputs": [],
      "source": [
        "sample_means = []\n",
        "for i in range(10000):\n",
        "    sample_means.append(np.random.choice(population, size=80).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIJhXIp3SKIw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "kbWpNADMJ1gH",
        "outputId": "bd14a4a8-1023-4495-e10a-4f5c83d23b49"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATUklEQVR4nO3df4zkdX3H8edbUCQchaPg5DyuLq1HW2AryAZpTJs9SfXUpIfREijRO0XPJlhrvDRF/9FKSTAtUA3WeorxqOJKUMMVsYZSt8Qmp94pcvwI5YQj3OY8BM7TVaTu+e4f+71z9pi9md3Z+fWZ5yOZ7Hc+38935jOfnXntZz/zme9EZiJJKssLet0ASdLSM9wlqUCGuyQVyHCXpAIZ7pJUoGN73QCAU089NUdGRprW+/nPf84JJ5zQ+QYNCPtjLvvj+eyTuUrrjx07djyVmac12tcX4T4yMsL27dub1pucnGR8fLzzDRoQ9sdc9sfz2SdzldYfEfH4fPuclpGkAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVqGm4R8SLI+I7EfGDiHggIv6+Kj8jIr4dEbsi4ksR8aKq/Ljq+q5q/0hnH4Ik6UitjNyfA16Tma8AzgXWRsSFwEeBGzLz5cB+4Iqq/hXA/qr8hqqeNDRGrvra4YvUK03DPWdNV1dfWF0SeA1wW1W+Bbi42l5XXafaf1FExJK1WJLUVLTyNXsRcQywA3g58AngH4Ft1eiciFgFfD0zz4mI+4G1mbmn2vdD4FWZ+dQRt7kR2AhQq9XOn5iYaNqO6elpli1btoCHVzb7Y65+6Y+dUwcOb4+uPKmHLemfPukXpfXHmjVrdmTmWKN9LZ04LDMPAudGxMnAV4E/aLdRmbkZ2AwwNjaWrZzMp7ST/rTL/pirX/pjQ910zO7Lx3vXEPqnT/rFMPXHgs4KmZk/iYhvAn8MnBwRx2bmDHA6MFVVmwJWAXsi4ljgJODpJWyz1BH1c+S7r31jD1sita+V1TKnVSN2IuJ44M+Ah4BvAm+pqq0Hbq+2t1bXqfb/V7Yy9yNJWjKtjNxXAFuqefcXALdm5h0R8SAwERH/AHwfuKmqfxPwbxGxC3gGuLQD7Zb6iitj1G+ahntm3gec16D8UeCCBuW/BP5iSVon9TEDXf3MT6hKUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAi3oE6rSIPKTpxpGhrvUQf5hUa84LSNJBTLcJalATstoaHn6AJXMcJcWwD8IGhROy0hSgRy5S004WtcgMtylBgx0DTrDXQOtPoQ/t/aEHrakOde8q5ucc5ekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtxVjJ1TBxi56muuUZcw3CWpSIa7JBWo6SdUI2IVcDNQAxLYnJkfi4gPA+8CflxV/WBm3lkd8wHgCuAg8N7M/EYH2i7Ny6kZDbtWTj8wA2zKzO9FxInAjoi4q9p3Q2b+U33liDgLuBQ4G3gp8J8RcWZmHlzKhkuS5td0WiYz92bm96rtnwEPASuPcsg6YCIzn8vMx4BdwAVL0VhJUmsiM1uvHDEC3AOcA7wf2AD8FNjO7Oh+f0TcCGzLzM9Xx9wEfD0zbzvitjYCGwFqtdr5ExMTTe9/enqaZcuWtdze0tkfsytkDqkdD/uePXr90ZUnNTy2l+rbtNR8jsxVWn+sWbNmR2aONdrX8lkhI2IZ8GXgfZn504j4JHA1s/PwVwPXAe9o9fYyczOwGWBsbCzHx8ebHjM5OUkr9YaF/QEb6ubWN43OcN3Ooz+ld18+3vDYXqpv01LzOTLXMPVHS+EeES9kNti/kJlfAcjMfXX7Pw3cUV2dAlbVHX56VSapAU8FrE5oOuceEQHcBDyUmdfXla+oq/Ym4P5qeytwaUQcFxFnAKuB7yxdkyVJzbQycn818FZgZ0TcW5V9ELgsIs5ldlpmN/BugMx8ICJuBR5kdqXNla6UkVrjKF5LpWm4Z+a3gGiw686jHHMNcE0b7ZIktcFPqEpSgQx3SSqQ4S5JBTLcJalALX+ISeq2+VaOeFIwqTlH7pJUIEfuGgiO1qWFceQuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCuRSSA2VQVpS6el/1Q5H7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoGahntErIqIb0bEgxHxQET8TVV+SkTcFRGPVD+XV+URER+PiF0RcV9EvLLTD0KSNFcrI/cZYFNmngVcCFwZEWcBVwF3Z+Zq4O7qOsDrgdXVZSPwySVvtSTpqJqGe2buzczvVds/Ax4CVgLrgC1VtS3AxdX2OuDmnLUNODkiVix5yyVJ81rQnHtEjADnAd8Gapm5t9r1I6BWba8Enqg7bE9VJknqkpbP5x4Ry4AvA+/LzJ9GxOF9mZkRkQu544jYyOy0DbVajcnJyabHTE9Pt1RvWJTYHzunDhze3jS6sGNrx8Om0ZklblF/WOzvucTnSDuGqT9aCveIeCGzwf6FzPxKVbwvIlZk5t5q2uXJqnwKWFV3+OlV2RyZuRnYDDA2Npbj4+NN2zE5OUkr9YZFif2xoY0v09g0OsN1O8v8/pndl48v6rgSnyPtGKb+aGW1TAA3AQ9l5vV1u7YC66vt9cDtdeVvq1bNXAgcqJu+kSR1QSvDnFcDbwV2RsS9VdkHgWuBWyPiCuBx4JJq353AG4BdwC+Aty9piyVJTTUN98z8FhDz7L6oQf0ErmyzXZKkNpQ5QSkVxi/L1kJ5+gFJKpDhLkkFMtwlqUDOuavnRtpY2y6pMUfuklQgw12SCmS4S1KBDHdJKpDhLkkFcrWMVKBDK5A2jc4w3tumqEccuUtSgQx3SSqQ4S5JBTLcJalAvqEqDTBPBaz5OHKXpAIZ7pJUIKdl1BOeCVLqLEfuklQgR+7SgPG/HrXCkbskFciRu7rGEafUPYa7VDjXwg8np2UkqUBNwz0iPhsRT0bE/XVlH46IqYi4t7q8oW7fByJiV0Q8HBGv61TDJUnza2Xk/jlgbYPyGzLz3OpyJ0BEnAVcCpxdHfMvEXHMUjVWktSapuGemfcAz7R4e+uAicx8LjMfA3YBF7TRPknSIrQz5/6eiLivmrZZXpWtBJ6oq7OnKpMkdVFkZvNKESPAHZl5TnW9BjwFJHA1sCIz3xERNwLbMvPzVb2bgK9n5m0NbnMjsBGgVqudPzEx0bQd09PTLFu2rLVHNgQGrT92Th3o6O3Xjod9z3b0Lvra6MqTDm8f6usj+6S+zjAatNdMM2vWrNmRmWON9i1qKWRm7ju0HRGfBu6ork4Bq+qqnl6VNbqNzcBmgLGxsRwfH296v5OTk7RSb1gMWn9s6PA6902jM1y3c3hX9+6+fPzw9oa671Ct75P6OsNo0F4z7VjUKyEiVmTm3urqm4BDK2m2ArdExPXAS4HVwHfabqWkpvyQmOo1DfeI+CIwDpwaEXuADwHjEXEus9Myu4F3A2TmAxFxK/AgMANcmZkHO9N0DQIDR+qNpuGemZc1KL7pKPWvAa5pp1GSpPYM7wSlNIQ8FcHw8PQDklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgrk6Qe0JPxYu9RfHLlLUoEMd0kqkNMyWnKew13qPUfuklQgR+6SfEO8QIa7Fs3pF6l/OS0jSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCuRSSGlIuZS1bI7cJalATcM9Ij4bEU9GxP11ZadExF0R8Uj1c3lVHhHx8YjYFRH3RcQrO9l4SVJjrUzLfA64Ebi5ruwq4O7MvDYirqqu/x3wemB1dXkV8Mnqpwrhv/LSYGg6cs/Me4BnjiheB2yptrcAF9eV35yztgEnR8SKpWqsJKk1i31DtZaZe6vtHwG1ansl8ERdvT1V2V6OEBEbgY0AtVqNycnJpnc6PT3dUr1h0Yv+2DQ609X7W4ja8f3dvl5YTJ+U/Bobpgxpe7VMZmZE5CKO2wxsBhgbG8vx8fGmx0xOTtJKvWHRrf6YOxXTvwusNo3OcN3O/m1fLyymT3ZfPt6ZxvSBYcqQxb4S9kXEiszcW027PFmVTwGr6uqdXpVpwDi3Lg22xS6F3Aqsr7bXA7fXlb+tWjVzIXCgbvpGktQlTUfuEfFFYBw4NSL2AB8CrgVujYgrgMeBS6rqdwJvAHYBvwDe3oE2S5KaaBrumXnZPLsualA3gSvbbZQkqT1+QlWSCmS4S1KBDHdJKpDhLkkFMtwlqUB+nE/SHEd+gG33tW/sUUvUDkfuklQgw12SCuS0zJCr/xfcf7+lcjhyl6QCOXKXdFT+dzeYDHdJi2Lo9zenZSSpQI7cJbXML3EZHI7cJalAjtwltc359/7jyF2SCuTIXYc5nyqVw3AfQoa4VD7DfQgY5tLwcc5dkgpkuEtSgQx3SSqQ4S5JBTLcJalAba2WiYjdwM+Ag8BMZo5FxCnAl4ARYDdwSWbub6+ZkqSFWIqR+5rMPDczx6rrVwF3Z+Zq4O7quiSpizoxLbMO2FJtbwEu7sB9SJKOIjJz8QdHPAbsBxL4VGZujoifZObJ1f4A9h+6fsSxG4GNALVa7fyJiYmm9zc9Pc2yZcsW3d7SHNkfO6cOHN4eXXlSw/KS1Y6Hfc/2uhX9pRd9Uv/c6zelZciaNWt21M2azNFuuK/MzKmIeAlwF/DXwNb6MI+I/Zm5/Gi3MzY2ltu3b296f5OTk4yPjy+6vaU5sj/mOzPfsHxCddPoDNft9EPX9XrRJ/18VsjSMiQi5g33tn7rmTlV/XwyIr4KXADsi4gVmbk3IlYAT7ZzH5IGSyuDiX7+A1CKRc+5R8QJEXHioW3gtcD9wFZgfVVtPXB7u42UJC1MOyP3GvDV2Wl1jgVuycz/iIjvArdGxBXA48Al7TdTkrQQiw73zHwUeEWD8qeBi9pplNo3LPPskhrzE6qSVCDDXZIK5LoxSV3nF2p3niN3SSqQ4S5JBXJaZsC5KkZSI47cJalAhrskFchpmT7migJJi2W4DwiDXqXyud0ZhrukvmTot8dw7zOuftEw8/m/dAz3AXToBbBpdAZ/hZIacbWMJBXIcJekAhnuklQgJ2wl9T1XziycI3dJKpAj9x5xJCItjq+d1hjufcC1vdLiGPTzM9wlFcGgn8tw7yJH6JK6xXCXNJRKH+kb7h3maF3qvvmCe+fUATYMyWvScG/BfE+U+YK7xFGApMHSsXCPiLXAx4BjgM9k5rWduq9uamUk7mhdUq91JNwj4hjgE8CfAXuA70bE1sx8cKnvq915M4NYKlv9a3zTaPM6i7HQ7OnGfH+nRu4XALsy81GAiJgA1gFLHu71jvwFzddpBrqkbujlm7aRmUt/oxFvAdZm5jur628FXpWZ76mrsxHYWF39feDhFm76VOCpJW7uILM/5rI/ns8+mau0/nhZZp7WaEfP3lDNzM3A5oUcExHbM3OsQ00aOPbHXPbH89kncw1Tf3TqxGFTwKq666dXZZKkLuhUuH8XWB0RZ0TEi4BLga0dui9J0hE6Mi2TmTMR8R7gG8wuhfxsZj6wBDe9oGmcIWB/zGV/PJ99MtfQ9EdH3lCVJPWWX9YhSQUy3CWpQH0R7hGxNiIejohdEXHVUeq9OSIyIsbqyj5QHfdwRLyuOy3uvMX2SUSMRMSzEXFvdfnX7rW6c5r1R0RsiIgf1z3ud9btWx8Rj1SX9d1teWe02R8H68qLWejQymsmIi6JiAcj4oGIuKWuvLjnCJnZ0wuzb7j+EPhd4EXAD4CzGtQ7EbgH2AaMVWVnVfWPA86obueYXj+mHvfJCHB/rx9Dt/sD2ADc2ODYU4BHq5/Lq+3lvX5MveqPat90rx9Dj/pkNfD9Q79/4CWlPkcysy9G7odPVZCZ/wccOlXBka4GPgr8sq5sHTCRmc9l5mPArur2Bl07fVKiVvujkdcBd2XmM5m5H7gLWNuhdnZLO/1Rqlb65F3AJ6rnAZn5ZFVe4nOkL8J9JfBE3fU9VdlhEfFKYFVmHnlSmKbHDqh2+gTgjIj4fkT8d0T8SQfb2S2t/p7fHBH3RcRtEXHoQ3QlPkfa6Q+AF0fE9ojYFhEXd7Sl3dNKn5wJnBkR/1M99rULOHbg9EO4H1VEvAC4HtjU67b0iyZ9shf4ncw8D3g/cEtE/FY329cj/w6MZOYfMTvy2tLj9vTa0frjZTn7Efy/BP45In6vFw3sgWOZnZoZBy4DPh0RJ/e0RR3UD+He7FQFJwLnAJMRsRu4ENhavYFY6mkOFt0n1RTV0wCZuYPZecgzu9Lqzmn6e87MpzPzuerqZ4DzWz12ALXTH2TmVPXzUWASOK+Tje2SVn7Pe4Ctmfmrahr3f5kN+xKfI33xhuqxzL6BcQa/eSPk7KPUn+Q3bx6ezdw3VB+ljDdU2+mT0w71AbNvLk0Bp/T6MXW6P4AVddtvArZV26cAjzH7RtnyanuY+2M5cFy1fSrwCA3erB+0S4t9shbYUvfYnwB+u8TnSGb2/mv2cp5TFUTER4DtmTnvUq2q3q3Mnid+BrgyMw92peEd1E6fAH8KfCQifgX8GvirzHym863unBb7470R8efMPg+eYXa1CJn5TERczez5jgA+Msz9Afwh8KmI+DWz/7lfmx34Ep1ua7FPvgG8NiIeBA4Cf5vVf7mlPUfA0w9IUpH6Yc5dkrTEDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUoP8HZeTHSlCu2bUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(sample_means, bins=100)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-76qlLztQfC"
      },
      "source": [
        "\n",
        "> Probability density function (pdf):\n",
        "\\begin{equation}\n",
        "f(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\n",
        "\\end{equation}\n",
        "\n",
        "> Likelihoods:\n",
        "\n",
        "\\begin{equation}\n",
        "p(x|y=0) \\sim N(\\mu_0, \\sigma_0^2)\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "p(x|y=1) \\sim N(\\mu_1, \\sigma_1^2)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "N9o7G-UbQnTs",
        "outputId": "f8bd7403-ab1e-4239-b348-3f8899d7db14"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-68302b2f4bd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df2' is not defined"
          ]
        }
      ],
      "source": [
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j03S2JV7LQDF"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "FTzR5dczTPsR",
        "outputId": "61765463-0f6d-4fc6-eb8a-256919376ba4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f6320641510>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.displot(df2[df2['malignant']==1]['mean radius'], kde=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPdbquMp2vyb"
      },
      "source": [
        "> Troubleshooting: If the above cell fails to run, upgrade seaborn by running the following in a new code cell:\n",
        "\n",
        "`!pip install seaborn==0.11.2`\n",
        "\n",
        "- Then, delete or comment out the cell you create, and restart the runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "ATicGhp-Mwv0",
        "outputId": "3f18c044-fa7a-427d-d657-c43c25cb266f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f6320750b10>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.displot(df2[df2['malignant']==0]['mean radius'], kde=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "nDI3dXXKMTPm",
        "outputId": "b59e9ef1-73f2-4509-d488-232ec6d40853"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-868aec807736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Malignant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'malignant'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean radius'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'malignant'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean radius'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df2' is not defined"
          ]
        }
      ],
      "source": [
        "# Malignant\n",
        "np.mean(df2[df2['malignant']==1]['mean radius']), np.var(df2[df2['malignant']==1]['mean radius'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePdQ3-EKM_xx",
        "outputId": "303e0180-8650-4f81-ef29-590120be3685"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(17.462830188679252, 10.217008971164114)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Benign\n",
        "np.mean(df2[df2['malignant']==0]['mean radius']), np.var(df2[df2['malignant']==0]['mean radius'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMM7UAwnMSTQ"
      },
      "source": [
        "- $p(x|y=1) \\sim N(12.15, 3.16)$\n",
        "- $p(x|y=0) \\sim N(17.46, 10.22)$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gweRTknsNssa"
      },
      "source": [
        "> Now, we evaluate the pdf:\n",
        "- $p(x=12.47 | y=1)$\n",
        "- $p(x=12.47 | y=0)$\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "f(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEYy8Nv2NsA4",
        "outputId": "2e1e5704-f4d4-4e2c-bf81-7fbbf9a61bba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.220815652167996"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# p(x=12.47| y= 1)\n",
        "\n",
        "f1 = 1/np.sqrt(2*np.pi*3.16) * np.exp(-0.5*(12.47- 12.15)**2/3.16)\n",
        "f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD4Vl1HmOtvo",
        "outputId": "2cd9b3b2-5946-48e1-8711-69e5501ec46f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.036908392064505836"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# p(x=12.47| y= 0)\n",
        "\n",
        "f0 = 1/np.sqrt(2*np.pi*10.22) * np.exp(-0.5*(12.47- 17.46)**2/10.22)\n",
        "f0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7QmKVb6QJK3"
      },
      "source": [
        "\\begin{equation}\n",
        "p(y=0|x) = \\frac{p(x|y=0)p(y=0)}{p(x)}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "p(y=1|x) = \\frac{p(x|y=1)p(y=1)}{p(x)}\n",
        "\\end{equation}\n",
        "\n",
        "> Prior probability\n",
        "- $p(y=1)$\n",
        "- $p(y=0)$\n",
        "\n",
        ">> Equiprobable priors\n",
        "- $p(y=1) = p(y=0) = 0.5$\n",
        "\n",
        ">> Empirical distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDq-HX13gdyg",
        "outputId": "89dfc26f-1225-4120-eb6e-b9b87c0922ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "357"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2[df2['malignant'] == 1].shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LugzTcaAWLSv",
        "outputId": "7bb0e648-a010-46a2-a970-9bc876890612"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "212"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2[df2['malignant'] == 0].shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xraAv_H0-Qh",
        "outputId": "68db1822-4e1f-4965-bf53-e75bf56347d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.6274165202108963, 0.37258347978910367)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p1 = 357/(357+212)\n",
        "p0 = 212/(357+212)\n",
        "p1, p0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il4pGlsk1WGQ"
      },
      "source": [
        "- $p(y=1) = 0.63$\n",
        "- $p(y=0) = 0.37$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acq5-k_x1g9H"
      },
      "source": [
        "\\begin{equation}\n",
        "p(y=1|x=12.47) = \\frac{0.22\\times 0.63}{p(x)}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "p(y=0|x=12.47) = \\frac{0.04\\times 0.37}{p(x)}\n",
        "\\end{equation}\n",
        "\n",
        "> Decide $y = 1$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR1wTDFyfrXu"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE-__ADewVXS"
      },
      "source": [
        "> Now, we consider the entire set of features $\\textbf{x}$:\n",
        ">> Including these extra features can improve prediction accuracy!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxhEQzxcwmc0",
        "outputId": "c2d9f622-e7b6-446b-daa1-5293084fc5b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "mean radius                 12.470000\n",
              "mean texture                18.600000\n",
              "mean perimeter              81.090000\n",
              "mean area                  481.900000\n",
              "mean smoothness              0.099650\n",
              "mean compactness             0.105800\n",
              "mean concavity               0.080050\n",
              "mean concave points          0.038210\n",
              "mean symmetry                0.192500\n",
              "mean fractal dimension       0.063730\n",
              "radius error                 0.396100\n",
              "texture error                1.044000\n",
              "perimeter error              2.497000\n",
              "area error                  30.290000\n",
              "smoothness error             0.006953\n",
              "compactness error            0.019110\n",
              "concavity error              0.027010\n",
              "concave points error         0.010370\n",
              "symmetry error               0.017820\n",
              "fractal dimension error      0.003586\n",
              "worst radius                14.970000\n",
              "worst texture               24.640000\n",
              "worst perimeter             96.050000\n",
              "worst area                 677.900000\n",
              "worst smoothness             0.142600\n",
              "worst compactness            0.237800\n",
              "worst concavity              0.267100\n",
              "worst concave points         0.101500\n",
              "worst symmetry               0.301400\n",
              "worst fractal dimension      0.087500\n",
              "Name: 204, dtype: float64"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# feature vector x\n",
        "df2.iloc[0,:-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MfZuutw1eoD"
      },
      "source": [
        "\\begin{equation}\n",
        "p(y=0|\\textbf{x}) = \\frac{p(\\textbf{x}|y=0)p(y=0)}{p(\\textbf{x})}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "p(y=1|\\textbf{x}) = \\frac{p(\\textbf{x}|y=1)p(y=1)}{p(\\textbf{x})}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{x} = [x_1, x_2, ..., x_d]\n",
        "\\end{equation}\n",
        "\n",
        "> $x_1, x_2, ..., x_d$ are not necessarily independent!\n",
        "- `mean radius` and `mean area`, for example, may be dependent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo8am06hQzn_"
      },
      "source": [
        "> Independence:\n",
        "\\begin{equation}\n",
        "p(A,B) = p(A) p(B)\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "> Assumption: Conditional independence:\n",
        "\n",
        "\\begin{equation}\n",
        "p(\\textbf{x}|y=0) = p(x_1|y=0)\\times p(x_2|y=0)\\times ...\\times p(x_d|y=0) = \\prod_{i=1}^d p(x_i|y=0)\n",
        "\\end{equation}\n",
        "\n",
        "Similarly,\n",
        "\\begin{equation}\n",
        "p(\\textbf{x}|y=1) = p(x_1|y=1)\\times p(x_2|y=1)\\times ...\\times p(x_d|y=1) = \\prod_{i=1}^d p(x_i|y=1)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i4CPXgY5Otr"
      },
      "source": [
        "\\begin{equation}\n",
        "p(y=0|\\textbf{x}) = \\frac{\\prod_{i=1}^d p(x_i|y=0)p(y=0)}{p(\\textbf{x})}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "p(y=1|\\textbf{x}) = \\frac{\\prod_{i=1}^d p(x_i|y=1)p(y=1)}{p(\\textbf{x})}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZOYuuoC4wTj"
      },
      "source": [
        "\\begin{equation}\n",
        "p(x_i|y=0) \\sim N(\\mu_{0,i}, \\sigma_{0,i}^2)\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "p(x_i|y=1) \\sim N(\\mu_{1,i}, \\sigma_{1,i}^2)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsxGXnEpOWEy"
      },
      "source": [
        "### Naive Bayes Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "aQiUehFH6C_g",
        "outputId": "443ce588-c7c8-496d-c6ba-5307010d21a8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5f056ebe-6a2d-4764-8057-ac5cc6ca0b25\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>malignant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>12.47</td>\n",
              "      <td>18.60</td>\n",
              "      <td>81.09</td>\n",
              "      <td>481.9</td>\n",
              "      <td>0.09965</td>\n",
              "      <td>0.1058</td>\n",
              "      <td>0.08005</td>\n",
              "      <td>0.03821</td>\n",
              "      <td>0.1925</td>\n",
              "      <td>0.06373</td>\n",
              "      <td>0.3961</td>\n",
              "      <td>1.0440</td>\n",
              "      <td>2.497</td>\n",
              "      <td>30.29</td>\n",
              "      <td>0.006953</td>\n",
              "      <td>0.01911</td>\n",
              "      <td>0.02701</td>\n",
              "      <td>0.01037</td>\n",
              "      <td>0.01782</td>\n",
              "      <td>0.003586</td>\n",
              "      <td>14.97</td>\n",
              "      <td>24.64</td>\n",
              "      <td>96.05</td>\n",
              "      <td>677.9</td>\n",
              "      <td>0.1426</td>\n",
              "      <td>0.2378</td>\n",
              "      <td>0.2671</td>\n",
              "      <td>0.10150</td>\n",
              "      <td>0.3014</td>\n",
              "      <td>0.08750</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>18.94</td>\n",
              "      <td>21.31</td>\n",
              "      <td>123.60</td>\n",
              "      <td>1130.0</td>\n",
              "      <td>0.09009</td>\n",
              "      <td>0.1029</td>\n",
              "      <td>0.10800</td>\n",
              "      <td>0.07951</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.05461</td>\n",
              "      <td>0.7888</td>\n",
              "      <td>0.7975</td>\n",
              "      <td>5.486</td>\n",
              "      <td>96.05</td>\n",
              "      <td>0.004444</td>\n",
              "      <td>0.01652</td>\n",
              "      <td>0.02269</td>\n",
              "      <td>0.01370</td>\n",
              "      <td>0.01386</td>\n",
              "      <td>0.001698</td>\n",
              "      <td>24.86</td>\n",
              "      <td>26.58</td>\n",
              "      <td>165.90</td>\n",
              "      <td>1866.0</td>\n",
              "      <td>0.1193</td>\n",
              "      <td>0.2336</td>\n",
              "      <td>0.2687</td>\n",
              "      <td>0.17890</td>\n",
              "      <td>0.2551</td>\n",
              "      <td>0.06589</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>15.46</td>\n",
              "      <td>19.48</td>\n",
              "      <td>101.70</td>\n",
              "      <td>748.9</td>\n",
              "      <td>0.10920</td>\n",
              "      <td>0.1223</td>\n",
              "      <td>0.14660</td>\n",
              "      <td>0.08087</td>\n",
              "      <td>0.1931</td>\n",
              "      <td>0.05796</td>\n",
              "      <td>0.4743</td>\n",
              "      <td>0.7859</td>\n",
              "      <td>3.094</td>\n",
              "      <td>48.31</td>\n",
              "      <td>0.006240</td>\n",
              "      <td>0.01484</td>\n",
              "      <td>0.02813</td>\n",
              "      <td>0.01093</td>\n",
              "      <td>0.01397</td>\n",
              "      <td>0.002461</td>\n",
              "      <td>19.26</td>\n",
              "      <td>26.00</td>\n",
              "      <td>124.90</td>\n",
              "      <td>1156.0</td>\n",
              "      <td>0.1546</td>\n",
              "      <td>0.2394</td>\n",
              "      <td>0.3791</td>\n",
              "      <td>0.15140</td>\n",
              "      <td>0.2837</td>\n",
              "      <td>0.08019</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>12.40</td>\n",
              "      <td>17.68</td>\n",
              "      <td>81.47</td>\n",
              "      <td>467.8</td>\n",
              "      <td>0.10540</td>\n",
              "      <td>0.1316</td>\n",
              "      <td>0.07741</td>\n",
              "      <td>0.02799</td>\n",
              "      <td>0.1811</td>\n",
              "      <td>0.07102</td>\n",
              "      <td>0.1767</td>\n",
              "      <td>1.4600</td>\n",
              "      <td>2.204</td>\n",
              "      <td>15.43</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.03295</td>\n",
              "      <td>0.04861</td>\n",
              "      <td>0.01167</td>\n",
              "      <td>0.02187</td>\n",
              "      <td>0.006005</td>\n",
              "      <td>12.88</td>\n",
              "      <td>22.91</td>\n",
              "      <td>89.61</td>\n",
              "      <td>515.8</td>\n",
              "      <td>0.1450</td>\n",
              "      <td>0.2629</td>\n",
              "      <td>0.2403</td>\n",
              "      <td>0.07370</td>\n",
              "      <td>0.2556</td>\n",
              "      <td>0.09359</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>11.54</td>\n",
              "      <td>14.44</td>\n",
              "      <td>74.65</td>\n",
              "      <td>402.9</td>\n",
              "      <td>0.09984</td>\n",
              "      <td>0.1120</td>\n",
              "      <td>0.06737</td>\n",
              "      <td>0.02594</td>\n",
              "      <td>0.1818</td>\n",
              "      <td>0.06782</td>\n",
              "      <td>0.2784</td>\n",
              "      <td>1.7680</td>\n",
              "      <td>1.628</td>\n",
              "      <td>20.86</td>\n",
              "      <td>0.012150</td>\n",
              "      <td>0.04112</td>\n",
              "      <td>0.05553</td>\n",
              "      <td>0.01494</td>\n",
              "      <td>0.01840</td>\n",
              "      <td>0.005512</td>\n",
              "      <td>12.26</td>\n",
              "      <td>19.68</td>\n",
              "      <td>78.78</td>\n",
              "      <td>457.8</td>\n",
              "      <td>0.1345</td>\n",
              "      <td>0.2118</td>\n",
              "      <td>0.1797</td>\n",
              "      <td>0.06918</td>\n",
              "      <td>0.2329</td>\n",
              "      <td>0.08134</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f056ebe-6a2d-4764-8057-ac5cc6ca0b25')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f056ebe-6a2d-4764-8057-ac5cc6ca0b25 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f056ebe-6a2d-4764-8057-ac5cc6ca0b25');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst fractal dimension  malignant\n",
              "204        12.47         18.60  ...                  0.08750          1\n",
              "70         18.94         21.31  ...                  0.06589          0\n",
              "131        15.46         19.48  ...                  0.08019          0\n",
              "431        12.40         17.68  ...                  0.09359          1\n",
              "540        11.54         14.44  ...                  0.08134          1\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrswuMvCOmdS"
      },
      "source": [
        "> Step 1: Extract labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "fHIbSnb96JYh",
        "outputId": "f165c337-916e-472a-e535-70baa824f3d7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a1b668e06b85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'malignant'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df2' is not defined"
          ]
        }
      ],
      "source": [
        "y = df2['malignant']\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iczwAfhUOrn6"
      },
      "source": [
        "> Step 2: Extract features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "TEAfKwn76dab",
        "outputId": "fbcd1f1b-01d6-4f1b-ce4b-fa3180f07eb9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a98fd51f-fd07-4d8f-ba48-9823bcd68cb8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>12.470</td>\n",
              "      <td>18.60</td>\n",
              "      <td>81.09</td>\n",
              "      <td>481.9</td>\n",
              "      <td>0.09965</td>\n",
              "      <td>0.10580</td>\n",
              "      <td>0.08005</td>\n",
              "      <td>0.03821</td>\n",
              "      <td>0.1925</td>\n",
              "      <td>0.06373</td>\n",
              "      <td>0.3961</td>\n",
              "      <td>1.0440</td>\n",
              "      <td>2.4970</td>\n",
              "      <td>30.29</td>\n",
              "      <td>0.006953</td>\n",
              "      <td>0.019110</td>\n",
              "      <td>0.027010</td>\n",
              "      <td>0.010370</td>\n",
              "      <td>0.01782</td>\n",
              "      <td>0.003586</td>\n",
              "      <td>14.970</td>\n",
              "      <td>24.64</td>\n",
              "      <td>96.05</td>\n",
              "      <td>677.9</td>\n",
              "      <td>0.14260</td>\n",
              "      <td>0.23780</td>\n",
              "      <td>0.26710</td>\n",
              "      <td>0.10150</td>\n",
              "      <td>0.3014</td>\n",
              "      <td>0.08750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>18.940</td>\n",
              "      <td>21.31</td>\n",
              "      <td>123.60</td>\n",
              "      <td>1130.0</td>\n",
              "      <td>0.09009</td>\n",
              "      <td>0.10290</td>\n",
              "      <td>0.10800</td>\n",
              "      <td>0.07951</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.05461</td>\n",
              "      <td>0.7888</td>\n",
              "      <td>0.7975</td>\n",
              "      <td>5.4860</td>\n",
              "      <td>96.05</td>\n",
              "      <td>0.004444</td>\n",
              "      <td>0.016520</td>\n",
              "      <td>0.022690</td>\n",
              "      <td>0.013700</td>\n",
              "      <td>0.01386</td>\n",
              "      <td>0.001698</td>\n",
              "      <td>24.860</td>\n",
              "      <td>26.58</td>\n",
              "      <td>165.90</td>\n",
              "      <td>1866.0</td>\n",
              "      <td>0.11930</td>\n",
              "      <td>0.23360</td>\n",
              "      <td>0.26870</td>\n",
              "      <td>0.17890</td>\n",
              "      <td>0.2551</td>\n",
              "      <td>0.06589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>15.460</td>\n",
              "      <td>19.48</td>\n",
              "      <td>101.70</td>\n",
              "      <td>748.9</td>\n",
              "      <td>0.10920</td>\n",
              "      <td>0.12230</td>\n",
              "      <td>0.14660</td>\n",
              "      <td>0.08087</td>\n",
              "      <td>0.1931</td>\n",
              "      <td>0.05796</td>\n",
              "      <td>0.4743</td>\n",
              "      <td>0.7859</td>\n",
              "      <td>3.0940</td>\n",
              "      <td>48.31</td>\n",
              "      <td>0.006240</td>\n",
              "      <td>0.014840</td>\n",
              "      <td>0.028130</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.01397</td>\n",
              "      <td>0.002461</td>\n",
              "      <td>19.260</td>\n",
              "      <td>26.00</td>\n",
              "      <td>124.90</td>\n",
              "      <td>1156.0</td>\n",
              "      <td>0.15460</td>\n",
              "      <td>0.23940</td>\n",
              "      <td>0.37910</td>\n",
              "      <td>0.15140</td>\n",
              "      <td>0.2837</td>\n",
              "      <td>0.08019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>12.400</td>\n",
              "      <td>17.68</td>\n",
              "      <td>81.47</td>\n",
              "      <td>467.8</td>\n",
              "      <td>0.10540</td>\n",
              "      <td>0.13160</td>\n",
              "      <td>0.07741</td>\n",
              "      <td>0.02799</td>\n",
              "      <td>0.1811</td>\n",
              "      <td>0.07102</td>\n",
              "      <td>0.1767</td>\n",
              "      <td>1.4600</td>\n",
              "      <td>2.2040</td>\n",
              "      <td>15.43</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.032950</td>\n",
              "      <td>0.048610</td>\n",
              "      <td>0.011670</td>\n",
              "      <td>0.02187</td>\n",
              "      <td>0.006005</td>\n",
              "      <td>12.880</td>\n",
              "      <td>22.91</td>\n",
              "      <td>89.61</td>\n",
              "      <td>515.8</td>\n",
              "      <td>0.14500</td>\n",
              "      <td>0.26290</td>\n",
              "      <td>0.24030</td>\n",
              "      <td>0.07370</td>\n",
              "      <td>0.2556</td>\n",
              "      <td>0.09359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>11.540</td>\n",
              "      <td>14.44</td>\n",
              "      <td>74.65</td>\n",
              "      <td>402.9</td>\n",
              "      <td>0.09984</td>\n",
              "      <td>0.11200</td>\n",
              "      <td>0.06737</td>\n",
              "      <td>0.02594</td>\n",
              "      <td>0.1818</td>\n",
              "      <td>0.06782</td>\n",
              "      <td>0.2784</td>\n",
              "      <td>1.7680</td>\n",
              "      <td>1.6280</td>\n",
              "      <td>20.86</td>\n",
              "      <td>0.012150</td>\n",
              "      <td>0.041120</td>\n",
              "      <td>0.055530</td>\n",
              "      <td>0.014940</td>\n",
              "      <td>0.01840</td>\n",
              "      <td>0.005512</td>\n",
              "      <td>12.260</td>\n",
              "      <td>19.68</td>\n",
              "      <td>78.78</td>\n",
              "      <td>457.8</td>\n",
              "      <td>0.13450</td>\n",
              "      <td>0.21180</td>\n",
              "      <td>0.17970</td>\n",
              "      <td>0.06918</td>\n",
              "      <td>0.2329</td>\n",
              "      <td>0.08134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>8.888</td>\n",
              "      <td>14.64</td>\n",
              "      <td>58.79</td>\n",
              "      <td>244.0</td>\n",
              "      <td>0.09783</td>\n",
              "      <td>0.15310</td>\n",
              "      <td>0.08606</td>\n",
              "      <td>0.02872</td>\n",
              "      <td>0.1902</td>\n",
              "      <td>0.08980</td>\n",
              "      <td>0.5262</td>\n",
              "      <td>0.8522</td>\n",
              "      <td>3.1680</td>\n",
              "      <td>25.44</td>\n",
              "      <td>0.017210</td>\n",
              "      <td>0.093680</td>\n",
              "      <td>0.056710</td>\n",
              "      <td>0.017660</td>\n",
              "      <td>0.02541</td>\n",
              "      <td>0.021930</td>\n",
              "      <td>9.733</td>\n",
              "      <td>15.67</td>\n",
              "      <td>62.56</td>\n",
              "      <td>284.4</td>\n",
              "      <td>0.12070</td>\n",
              "      <td>0.24360</td>\n",
              "      <td>0.14340</td>\n",
              "      <td>0.04786</td>\n",
              "      <td>0.2254</td>\n",
              "      <td>0.10840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>11.640</td>\n",
              "      <td>18.33</td>\n",
              "      <td>75.17</td>\n",
              "      <td>412.5</td>\n",
              "      <td>0.11420</td>\n",
              "      <td>0.10170</td>\n",
              "      <td>0.07070</td>\n",
              "      <td>0.03485</td>\n",
              "      <td>0.1801</td>\n",
              "      <td>0.06520</td>\n",
              "      <td>0.3060</td>\n",
              "      <td>1.6570</td>\n",
              "      <td>2.1550</td>\n",
              "      <td>20.62</td>\n",
              "      <td>0.008540</td>\n",
              "      <td>0.023100</td>\n",
              "      <td>0.029450</td>\n",
              "      <td>0.013980</td>\n",
              "      <td>0.01565</td>\n",
              "      <td>0.003840</td>\n",
              "      <td>13.140</td>\n",
              "      <td>29.26</td>\n",
              "      <td>85.51</td>\n",
              "      <td>521.7</td>\n",
              "      <td>0.16880</td>\n",
              "      <td>0.26600</td>\n",
              "      <td>0.28730</td>\n",
              "      <td>0.12180</td>\n",
              "      <td>0.2806</td>\n",
              "      <td>0.09097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>14.290</td>\n",
              "      <td>16.82</td>\n",
              "      <td>90.30</td>\n",
              "      <td>632.6</td>\n",
              "      <td>0.06429</td>\n",
              "      <td>0.02675</td>\n",
              "      <td>0.00725</td>\n",
              "      <td>0.00625</td>\n",
              "      <td>0.1508</td>\n",
              "      <td>0.05376</td>\n",
              "      <td>0.1302</td>\n",
              "      <td>0.7198</td>\n",
              "      <td>0.8439</td>\n",
              "      <td>10.77</td>\n",
              "      <td>0.003492</td>\n",
              "      <td>0.003710</td>\n",
              "      <td>0.004826</td>\n",
              "      <td>0.003608</td>\n",
              "      <td>0.01536</td>\n",
              "      <td>0.001381</td>\n",
              "      <td>14.910</td>\n",
              "      <td>20.65</td>\n",
              "      <td>94.44</td>\n",
              "      <td>684.6</td>\n",
              "      <td>0.08567</td>\n",
              "      <td>0.05036</td>\n",
              "      <td>0.03866</td>\n",
              "      <td>0.03333</td>\n",
              "      <td>0.2458</td>\n",
              "      <td>0.06120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>13.980</td>\n",
              "      <td>19.62</td>\n",
              "      <td>91.12</td>\n",
              "      <td>599.5</td>\n",
              "      <td>0.10600</td>\n",
              "      <td>0.11330</td>\n",
              "      <td>0.11260</td>\n",
              "      <td>0.06463</td>\n",
              "      <td>0.1669</td>\n",
              "      <td>0.06544</td>\n",
              "      <td>0.2208</td>\n",
              "      <td>0.9533</td>\n",
              "      <td>1.6020</td>\n",
              "      <td>18.85</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.017910</td>\n",
              "      <td>0.021850</td>\n",
              "      <td>0.009567</td>\n",
              "      <td>0.01223</td>\n",
              "      <td>0.002846</td>\n",
              "      <td>17.040</td>\n",
              "      <td>30.80</td>\n",
              "      <td>113.90</td>\n",
              "      <td>869.3</td>\n",
              "      <td>0.16130</td>\n",
              "      <td>0.35680</td>\n",
              "      <td>0.40690</td>\n",
              "      <td>0.18270</td>\n",
              "      <td>0.3179</td>\n",
              "      <td>0.10550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>12.180</td>\n",
              "      <td>20.52</td>\n",
              "      <td>77.22</td>\n",
              "      <td>458.7</td>\n",
              "      <td>0.08013</td>\n",
              "      <td>0.04038</td>\n",
              "      <td>0.02383</td>\n",
              "      <td>0.01770</td>\n",
              "      <td>0.1739</td>\n",
              "      <td>0.05677</td>\n",
              "      <td>0.1924</td>\n",
              "      <td>1.5710</td>\n",
              "      <td>1.1830</td>\n",
              "      <td>14.68</td>\n",
              "      <td>0.005080</td>\n",
              "      <td>0.006098</td>\n",
              "      <td>0.010690</td>\n",
              "      <td>0.006797</td>\n",
              "      <td>0.01447</td>\n",
              "      <td>0.001532</td>\n",
              "      <td>13.340</td>\n",
              "      <td>32.84</td>\n",
              "      <td>84.58</td>\n",
              "      <td>547.8</td>\n",
              "      <td>0.11230</td>\n",
              "      <td>0.08862</td>\n",
              "      <td>0.11450</td>\n",
              "      <td>0.07431</td>\n",
              "      <td>0.2694</td>\n",
              "      <td>0.06878</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a98fd51f-fd07-4d8f-ba48-9823bcd68cb8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a98fd51f-fd07-4d8f-ba48-9823bcd68cb8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a98fd51f-fd07-4d8f-ba48-9823bcd68cb8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "204       12.470         18.60  ...          0.3014                  0.08750\n",
              "70        18.940         21.31  ...          0.2551                  0.06589\n",
              "131       15.460         19.48  ...          0.2837                  0.08019\n",
              "431       12.400         17.68  ...          0.2556                  0.09359\n",
              "540       11.540         14.44  ...          0.2329                  0.08134\n",
              "..           ...           ...  ...             ...                      ...\n",
              "71         8.888         14.64  ...          0.2254                  0.10840\n",
              "106       11.640         18.33  ...          0.2806                  0.09097\n",
              "270       14.290         16.82  ...          0.2458                  0.06120\n",
              "435       13.980         19.62  ...          0.3179                  0.10550\n",
              "102       12.180         20.52  ...          0.2694                  0.06878\n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We simply drop the label\n",
        "X = df2.drop(columns='malignant')\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RecraaVZOytd"
      },
      "source": [
        "> Step 3: We split the data into training and test sets\n",
        "- Here, we're splitting to a ratio of $80: 20$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU2aSC3S52U9",
        "outputId": "f93e98ce-38c7-451f-e836-40249db58197"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((455, 30), (114, 30), (455,), (114,))"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train - test split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIt-y1eOPFK0",
        "outputId": "7cf5060b-08f1-4061-9f3e-f6038ba6fae6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.7996485061511424, 0.20035149384885764)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "455/569, 114/569"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRs5r7pO3c5n",
        "outputId": "4148896c-c9e7-450f-f9a7-e37a915722aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d = X_train.shape[1]\n",
        "d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LhxNqOqORD8"
      },
      "source": [
        "> Step 4: In the training set `X_train`, we want to separate Class 1 (malignant) and Class 0 (benign), so that we can find the mean and variance of their features.\n",
        "\n",
        "\\begin{equation}\n",
        "p(x_i|y=0) \\sim N(\\mu_{0,i}, \\sigma_{0,i}^2)\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "p(x_i|y=1) \\sim N(\\mu_{1,i}, \\sigma_{1,i}^2)\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "p(y=0|\\textbf{x}) = \\frac{\\prod_{i=1}^d p(x_i|y=0)p(y=0)}{p(\\textbf{x})}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "p(y=1|\\textbf{x}) = \\frac{\\prod_{i=1}^d p(x_i|y=1)p(y=1)}{p(\\textbf{x})}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhdlZD1Y9lce"
      },
      "outputs": [],
      "source": [
        "X_train_1 = X_train[y_train == 1]\n",
        "\n",
        "X_train_0 = X_train[y_train == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA9WbSCoNXOx",
        "outputId": "ccd579f1-fe61-4d86-d0ed-59c139736bb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "mean radius                 12.129789\n",
              "mean texture                17.993080\n",
              "mean perimeter              77.981869\n",
              "mean area                  461.155017\n",
              "mean smoothness              0.092749\n",
              "mean compactness             0.080785\n",
              "mean concavity               0.046435\n",
              "mean concave points          0.025961\n",
              "mean symmetry                0.174608\n",
              "mean fractal dimension       0.063018\n",
              "radius error                 0.287942\n",
              "texture error                1.250289\n",
              "perimeter error              2.020202\n",
              "area error                  21.397239\n",
              "smoothness error             0.007325\n",
              "compactness error            0.021562\n",
              "concavity error              0.026268\n",
              "concave points error         0.009920\n",
              "symmetry error               0.020910\n",
              "fractal dimension error      0.003650\n",
              "worst radius                13.350761\n",
              "worst texture               23.586125\n",
              "worst perimeter             86.774810\n",
              "worst area                 556.110381\n",
              "worst smoothness             0.125072\n",
              "worst compactness            0.182172\n",
              "worst concavity              0.165644\n",
              "worst concave points         0.074018\n",
              "worst symmetry               0.270333\n",
              "worst fractal dimension      0.079447\n",
              "dtype: float64"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Gives the means of all the features for class 1 (malignant) in the training set\n",
        "mu_1 = np.mean(X_train_1, axis=0)\n",
        "mu_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsOWdmgNGauD",
        "outputId": "04e995b9-aeaa-4d77-f267-48fe86d4e75d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "mean radius                    3.099403\n",
              "mean texture                  15.899684\n",
              "mean perimeter               137.462447\n",
              "mean area                  17313.814724\n",
              "mean smoothness                0.000173\n",
              "mean compactness               0.001144\n",
              "mean concavity                 0.002025\n",
              "mean concave points            0.000266\n",
              "mean symmetry                  0.000596\n",
              "mean fractal dimension         0.000042\n",
              "radius error                   0.013170\n",
              "texture error                  0.381492\n",
              "perimeter error                0.622575\n",
              "area error                    81.125242\n",
              "smoothness error               0.000010\n",
              "compactness error              0.000266\n",
              "concavity error                0.001200\n",
              "concave points error           0.000034\n",
              "symmetry error                 0.000051\n",
              "fractal dimension error        0.000009\n",
              "worst radius                   3.776127\n",
              "worst texture                 30.456546\n",
              "worst perimeter              176.549414\n",
              "worst area                 25243.416570\n",
              "worst smoothness               0.000392\n",
              "worst compactness              0.008429\n",
              "worst concavity                0.020460\n",
              "worst concave points           0.001254\n",
              "worst symmetry                 0.001689\n",
              "worst fractal dimension        0.000187\n",
              "dtype: float64"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Gives the variances of all the features for class 1 (malignant) in the training set\n",
        "var_1 = np.var(X_train_1, axis=0)\n",
        "var_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DxpfyXLGqm2",
        "outputId": "679fabfd-b8fc-4f1b-d946-4b62b47594c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((30,), (30,))"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mu_0 = np.mean(X_train_0, axis=0)\n",
        "var_0 = np.var(X_train_0, axis=0)\n",
        "mu_0.shape, var_0.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC602QDM3c5o"
      },
      "source": [
        "> Step 5: We need to evaluate the prior probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g6hvf2H3c5o",
        "outputId": "2fbc66a1-0c0d-459d-aeaf-ca118e5f6192"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6351648351648351"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_1 = len(y_train[y_train == 1])/len(y_train)\n",
        "p_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgoiBr073c5o",
        "outputId": "f6ca2364-309e-438d-8f02-4ae564f14387"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.3648351648351648"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_0 = len(y_train[y_train == 0])/len(y_train)\n",
        "p_0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS3dOIQRH2Fe"
      },
      "source": [
        "> Training is complete!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_ZnHbnf3c5o"
      },
      "source": [
        "> Step 6: Testing\n",
        "- To test the Naive Bayes model, we need to evaluate the following for each sample $\\textbf{x}$ in the test set:\n",
        "\n",
        "\\begin{equation}\n",
        "p(y=0|\\textbf{x}) = \\frac{\\prod_{i=1}^d p(x_i|y=0)p(y=0)}{p(\\textbf{x})}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "p(y=1|\\textbf{x}) = \\frac{\\prod_{i=1}^d p(x_i|y=1)p(y=1)}{p(\\textbf{x})}\n",
        "\\end{equation}\n",
        "\n",
        "- We define a function to help us with the evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cu-JdGu83c5p"
      },
      "outputs": [],
      "source": [
        "def pdf(x, y):\n",
        "    \"\"\"\n",
        "    x: input (d-dimensional) vector of features from the test set\n",
        "    y: input hypothesis: y=0 (benign), y=1 (malignant)\n",
        "    \n",
        "    joint_prob: the joint pdf of x under the hypothesis that y=0, or y=1\n",
        "    \"\"\"\n",
        "    probs = []\n",
        "    for j in range(d):\n",
        "        if y == 1:\n",
        "            prob = 1/np.sqrt(2*np.pi*var_1[j]) * np.exp(-0.5*(x[j]- mu_1[j])**2/var_1[j])\n",
        "        elif y == 0:\n",
        "            prob = 1/np.sqrt(2*np.pi*var_0[j]) * np.exp(-0.5*(x[j]- mu_0[j])**2/var_0[j])\n",
        "        probs.append(prob)\n",
        "    joint_prob = np.prod(probs)\n",
        "    \n",
        "    return joint_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TriYOJqG3c5p",
        "outputId": "4b7fd620-0bf7-4053-fc7c-61cb4a6f79c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "114"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gu9UUUNs3c5p"
      },
      "outputs": [],
      "source": [
        "y_predicted = []\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "    x_i = X_test.iloc[i,:]\n",
        "    \n",
        "    # Assuming y = 1\n",
        "    joint_prob_1 = pdf(x_i, y=1)\n",
        "    posterior_prob_1 = joint_prob_1 * p_1\n",
        "    \n",
        "    # Assuming y = 0\n",
        "    joint_prob_0 = pdf(x_i, y=0)\n",
        "    posterior_prob_0 = joint_prob_0 * p_0\n",
        "    \n",
        "    if posterior_prob_1 > posterior_prob_0:\n",
        "        predicted = 1\n",
        "    else:\n",
        "        predicted = 0\n",
        "        \n",
        "    y_predicted.append(predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFM6XuPi3c5p"
      },
      "source": [
        "> Step 7: We now compute the accuracy of our predictions on the test set `y_test`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebwSOQYX3c5p",
        "outputId": "97c7deae-613a-4e48-aba1-3cee7154430a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9035087719298246"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diff = y_predicted - y_test # y_test is the true labels from the holdout or test set\n",
        "\n",
        "len(diff[diff==0])/len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOcuDgSx3c5p"
      },
      "source": [
        "> ***90.35% accuracy!***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9foOE4Tfv2F"
      },
      "source": [
        "## Quadratic Discriminant Analysis (QDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2wiNKwf3c5q"
      },
      "source": [
        "> We eliminate the naive independence assumption in Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgOrYi1k3c5q"
      },
      "source": [
        "\\begin{equation}\n",
        "p(y=0|\\textbf{x}) = \\frac{p(\\textbf{x}|y=0)p(y=0)}{p(\\textbf{x})}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "p(y=1|\\textbf{x}) = \\frac{p(\\textbf{x}|y=1)p(y=1)}{p(\\textbf{x})}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydpbXLtR3c5q"
      },
      "source": [
        "> We can take ratios as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihDuR2Wx3c5q"
      },
      "source": [
        "\\begin{equation}\n",
        "\\frac{p(y=0|\\textbf{x})}{p(y=1|\\textbf{x})} \\mathop{\\lessgtr}_{y=0}^{y=1} 1\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta7KYzn6usGX"
      },
      "source": [
        "> MAP rule:\n",
        "\\begin{equation}\n",
        "\\frac{p(\\textbf{x}|y=0)p(y=0)}{p(\\textbf{x}|y=1)p(y=1)} \\mathop{\\lessgtr}_{y=0}^{y=1} 1\n",
        "\\end{equation}\n",
        "\n",
        "which simplifies to:\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{p(\\textbf{x}|y=0)}{p(\\textbf{x}|y=1)} \\mathop{\\lessgtr}_{y=0}^{y=1} \\frac{p(y=1)}{p(y=0)}\n",
        "\\end{equation}\n",
        "\n",
        "> Define likelihood ratio $\\lambda$\n",
        "\\begin{equation}\n",
        "\\lambda = \\frac{p(\\textbf{x}|y=0)}{p(\\textbf{x}|y=1)}\n",
        "\\end{equation}\n",
        "\n",
        "> Define $\\tau$\n",
        "\\begin{equation}\n",
        "\\tau = \\frac{p(y=1)}{p(y=0)}\n",
        "\\end{equation}\n",
        "\n",
        "Therefore, decision rule is:\n",
        "\\begin{equation}\n",
        "\\lambda \\mathop{\\lessgtr}_{y=0}^{y=1} \\tau\n",
        "\\end{equation}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvnSdgYe3c5q"
      },
      "source": [
        "> We still assume a Gaussian distribution\n",
        "- ... except this time, a **multivariate Gaussian** distribution\n",
        "- this ensures that the features in $\\textbf{x}$ are jointly distributed with a covariance structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDkMH6de3c5q"
      },
      "source": [
        "### Multivariate Gaussian distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94d1Ay8e3c5r"
      },
      "source": [
        "> Probability density function (pdf):\n",
        "    \n",
        "\\begin{equation}\n",
        "f(\\textbf{x}; \\textbf{m}, \\textbf{K}) = \\frac{1}{\\sqrt{(2\\pi)^d\\det{(\\textbf{K})}}}e^{-\\frac{1}{2}(\\textbf{x}-\\textbf{m})^\\top \\textbf{K}^{-1} (\\textbf{x}-\\textbf{m})}\n",
        "\\end{equation}\n",
        "\n",
        "where\n",
        "$\\textbf{m}$ is the mean of the feature vector $\\textbf{x}$, and\n",
        "$\\textbf{K}$ is the covariance matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUl1knM43c5r"
      },
      "source": [
        "\\begin{equation}\n",
        "p(\\textbf{x}|y=0) \\sim N(\\textbf{m}_{0}, \\textbf{K}_0)\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "p(\\textbf{x}|y=1) \\sim N(\\textbf{m}_{1}, \\textbf{K}_1)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7ZiwPib3c5r"
      },
      "source": [
        "> Therefore,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h62Sq8n3c5r"
      },
      "source": [
        "\\begin{equation}\n",
        "\\frac{p(\\textbf{x}|y=0)}{p(\\textbf{x}|y=1)} \\mathop{\\lessgtr}_{y=0}^{y=1} \\frac{p(y=1)}{p(y=0)}\n",
        "\\end{equation}\n",
        "\n",
        "> becomes:\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\sqrt{\\det{(\\textbf{K}_1)}} e^{-\\frac{1}{2}(\\textbf{x}-\\textbf{m}_0)^\\top \\textbf{K}_0^{-1} (\\textbf{x}-\\textbf{m}_0)}}{\\sqrt{\\det{(\\textbf{K}_0)}}e^{-\\frac{1}{2}(\\textbf{x}-\\textbf{m}_1)^\\top \\textbf{K}_1^{-1} (\\textbf{x}-\\textbf{m}_1)}} \\mathop{\\lessgtr}_{y=0}^{y=1} \\frac{p(y=1)}{p(y=0)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTC7aEEa3c5r"
      },
      "source": [
        "> We can then simplify to:\n",
        "\n",
        "\\begin{equation}\n",
        "e^{\\frac{1}{2}\\big[(\\textbf{x}-\\textbf{m}_1)^\\top \\textbf{K}_1^{-1} (\\textbf{x}-\\textbf{m}_1) - (\\textbf{x}-\\textbf{m}_0)^\\top \\textbf{K}_0^{-1} (\\textbf{x}-\\textbf{m}_0)\\big]} \\mathop{\\lessgtr}_{y=0}^{y=1} \\sqrt{\\frac{\\det{(\\textbf{K}_0)}}{\\det{(\\textbf{K}_1)}}} \\frac{p(y=1)}{p(y=0)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM3kqhbG3c5s"
      },
      "source": [
        "> We can then take logs:\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{1}{2}\\bigg[(\\textbf{x}-\\textbf{m}_1)^\\top \\textbf{K}_1^{-1} (\\textbf{x}-\\textbf{m}_1) - (\\textbf{x}-\\textbf{m}_0)^\\top \\textbf{K}_0^{-1} (\\textbf{x}-\\textbf{m}_0)\\bigg] \\mathop{\\lessgtr}_{y=0}^{y=1} \\frac{1}{2}\\log{\\frac{\\det{(\\textbf{K}_0)}}{\\det{(\\textbf{K}_1)}}} + \\log{\\frac{p(y=1)}{p(y=0)}}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vegK1QaP3c5s"
      },
      "source": [
        "> Multiply through by 2 and simplify:\n",
        "\n",
        "\\begin{equation}\n",
        "(\\textbf{x}-\\textbf{m}_1)^\\top \\textbf{K}_1^{-1} (\\textbf{x}-\\textbf{m}_1) - (\\textbf{x}-\\textbf{m}_0)^\\top \\textbf{K}_0^{-1} (\\textbf{x}-\\textbf{m}_0) \\mathop{\\lessgtr}_{y=0}^{y=1} \\log{\\frac{\\det{(\\textbf{K}_0)}}{\\det{(\\textbf{K}_1)}}} + 2\\log{\\frac{p(y=1)}{p(y=0)}}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRug-8dGBJDX"
      },
      "source": [
        "> We obtain:\n",
        "\\begin{equation}\n",
        "(\\textbf{x}-\\textbf{m}_1)^\\top \\textbf{K}_1^{-1} (\\textbf{x}-\\textbf{m}_1) - (\\textbf{x}-\\textbf{m}_0)^\\top \\textbf{K}_0^{-1} (\\textbf{x}-\\textbf{m}_0) \\mathop{\\lessgtr}_{y=0}^{y=1} \\log{\\frac{\\tau^2 \\det{(\\textbf{K}_0)}}{\\det{(\\textbf{K}_1)}}}\n",
        "\\end{equation}\n",
        "\n",
        "> where\n",
        "\\begin{equation}\n",
        "\\tau = \\frac{p(y=1)}{p(y=0)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CayBCzNg3c5s"
      },
      "source": [
        "> In standard form:\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{x}^\\top \\textbf{A} \\textbf{x} + \\textbf{b}^\\top\\textbf{x} + c \\mathop{\\lessgtr}_{y=0}^{y=1} 0\n",
        "\\end{equation}\n",
        "\n",
        "> where:\n",
        "\n",
        "\\begin{align}\n",
        "& \\textbf{A} = (\\textbf{K}_1^{-1} - \\textbf{K}_0^{-1}) \\\\\n",
        "& \\textbf{b} = -2(\\textbf{K}_1^{-1}\\textbf{m}_1 - \\textbf{K}_0^{-1}\\textbf{m}_0) \\\\\n",
        "& c = \\textbf{m}_1^\\top\\textbf{K}_1^{-1}\\textbf{m}_1 - \\textbf{m}_0^\\top\\textbf{K}_0^{-1}\\textbf{m}_0 - \\log{\\frac{\\tau^2 \\det{(\\textbf{K}_0)}}{\\det{(\\textbf{K}_1)}}}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "walq41y33c5s"
      },
      "source": [
        "> A quadratic function in terms of $\\textbf{x}$!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqz5KDpe3c5t"
      },
      "source": [
        "### QDA code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS08I0IO3c5t",
        "outputId": "d8e70939-bff2-456b-d23e-beb4a7e30cd3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((455, 30), (114, 30), (455,), (114,))"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmFG4dfD3c5t"
      },
      "source": [
        "> Step 1: In the training set `X_train`, we want to separate class 1 (malignant) from class 0 (benign)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziBMqqEg3c5t"
      },
      "outputs": [],
      "source": [
        "X_train_1 = X_train[y_train == 1]\n",
        "\n",
        "X_train_0 = X_train[y_train == 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XXOclyg3c5t"
      },
      "source": [
        "> Step 2: Compute $\\textbf{A}, \\textbf{b}$ and $c$ from the training set\n",
        "- To compute these, we need to compute 5 things:\n",
        " - $\\textbf{m}_1, \\textbf{m}_0, \\textbf{K}_1, \\textbf{K}_0, \\tau$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN4pJy-L3c5u",
        "outputId": "d8e92b0f-c03a-4331-a95b-ba806ae59ca8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((30, 30), (30, 30))"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Gives the means of all the features for class 1 (malignant) in the training set\n",
        "m_1 = np.mean(X_train_1, axis=0)\n",
        "\n",
        "# Gives the means of all the features for class 0 (malignant) in the training set\n",
        "m_0 = np.mean(X_train_0, axis=0)\n",
        "\n",
        "# Gives the covariance of all the features for class 1 (malignant) in the training set\n",
        "K_1 = np.cov(X_train_1, rowvar=False)\n",
        "\n",
        "# Gives the covariance of all the features for class 0 (benign) in the training set\n",
        "K_0 = np.cov(X_train_0, rowvar=False)\n",
        "\n",
        "K_1.shape, K_0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL2gD4uO3c5u",
        "outputId": "ba3ede83-152f-46b8-d41d-66697739c6cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30, 30)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A = (np.linalg.pinv(K_1) - np.linalg.pinv(K_0))\n",
        "A.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-JKSqXS3c5u",
        "outputId": "1ebb2d08-dc6a-4f23-ae53-0d9d2370a4d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30,)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = -2*(np.linalg.pinv(K_1)@m_1 - np.linalg.pinv(K_0)@m_0)\n",
        "b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXwrlA2V3c5u",
        "outputId": "d46f4c91-94a6-4a3e-c4cc-970e23af35d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-141.00688008780392"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_1 = len(y_train[y_train == 1])/len(y_train)\n",
        "p_0 = len(y_train[y_train == 0])/len(y_train)\n",
        "tau = p_1/p_0\n",
        "c = m_1.T@np.linalg.pinv(K_1)@m_1 - m_0.T@np.linalg.pinv(K_0)@m_0 - np.log(tau**2 * np.linalg.det(K_0)/ np.linalg.det(K_1))\n",
        "c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTeJJzaQ3c5u"
      },
      "source": [
        "> Step 3: we need to evaluate the following for each sample in the test set `X_test`:\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{x}^\\top \\textbf{A} \\textbf{x} + \\textbf{b}^\\top\\textbf{x} + c \\mathop{\\lessgtr}_{y=0}^{y=1} 0\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EykI7BGO3c5v"
      },
      "outputs": [],
      "source": [
        "y_predicted_qda = []\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "    x_i = X_test.iloc[i,:]\n",
        "    \n",
        "    quad_func = x_i.T@A@x_i + b.T@x_i + c\n",
        "    \n",
        "    if quad_func > 0:\n",
        "        predicted = 0\n",
        "    else:\n",
        "        predicted = 1\n",
        "        \n",
        "    y_predicted_qda.append(predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA46dweG3c5v"
      },
      "source": [
        "> Step 4: We now compute the accuracy of our predictions on the test set `y_test`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyg90kKr3c5v",
        "outputId": "16a58012-7613-4f9e-db16-584d32018a67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9122807017543859"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diff = y_predicted_qda - y_test # y_test is the true labels from the holdout or test set\n",
        "\n",
        "len(diff[diff==0])/len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT24bZKJ3c5v"
      },
      "source": [
        "> ***91.22% accuracy!***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GGdPHgTf1XZ"
      },
      "source": [
        "## Linear Discriminant Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5ideYAU3c5v"
      },
      "source": [
        "> Task: We want the following decision rule to be linear\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{x}^\\top \\textbf{A} \\textbf{x} + \\textbf{b}^\\top\\textbf{x} + c \\mathop{\\lessgtr}_{y=0}^{y=1} 0\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVNg1f-23c5v"
      },
      "source": [
        "> Why?\n",
        "- Robust (even if the multivariate Gaussian assumption does not hold)\n",
        "- Kernelisable (allows for learning arbitrary non-linear decision boundaries)\n",
        "- Fast training and testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWoKRuhe3c5w"
      },
      "source": [
        "### Homoscedasticity\n",
        "- Assumption of equal covariance between classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySrrizgM3c5w"
      },
      "source": [
        "$\\textbf{K}_1 = \\textbf{K}_0 = \\textbf{K}$\n",
        "\n",
        "Some common covariance matrix $\\textbf{K}$\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{K} = \\frac{1}{n_1 + n_0}(n_1 \\textbf{K}_1 + n_0 \\textbf{K}_0)\n",
        "\\end{equation}\n",
        "\n",
        "where\n",
        "\n",
        "$n_1$ is the number of samples in class 1 in the training set `X_train`\n",
        "\n",
        "$n_0$ is the number of samples in class 0 in the training set `X_train`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4x0slOs3c5w"
      },
      "source": [
        "\\begin{align}\n",
        "& \\textbf{A} = (\\textbf{K}_1^{-1} - \\textbf{K}_0^{-1}) \\\\\n",
        "& \\textbf{b} = -2(\\textbf{K}_1^{-1}\\textbf{m}_1 - \\textbf{K}_0^{-1}\\textbf{m}_0) \\\\\n",
        "& c = \\textbf{m}_1^\\top\\textbf{K}_1^{-1}\\textbf{m}_1 - \\textbf{m}_0^\\top\\textbf{K}_0^{-1}\\textbf{m}_0 - \\log{\\frac{\\tau^2 \\det{(\\textbf{K}_0)}}{\\det{(\\textbf{K}_1)}}}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-BnVyQt3c5w"
      },
      "source": [
        "> Results of homosecedasticity assumption:\n",
        "\n",
        "\\begin{align}\n",
        "& \\textbf{A} = 0 \\\\\n",
        "& \\textbf{b} = -2\\textbf{K}^{-1}(\\textbf{m}_1 - \\textbf{m}_0) \\\\\n",
        "& c = \\textbf{m}_1^\\top\\textbf{K}^{-1}\\textbf{m}_1 - \\textbf{m}_0^\\top\\textbf{K}^{-1}\\textbf{m}_0 - 2\\log{\\tau}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyGalwmf3c5w"
      },
      "source": [
        "> Decision rule becomes linear:\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{b}^\\top\\textbf{x} + c \\mathop{\\lessgtr}_{y=0}^{y=1} 0\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LR0ec2o3c5w"
      },
      "source": [
        "### LDA code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lkfdulC3c5w"
      },
      "source": [
        "> Step 1: In the training set `X_train`, we want to separate class 1 (malignant) from class 0 (benign)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeDdzF7R3c5w"
      },
      "outputs": [],
      "source": [
        "X_train_1 = X_train[y_train == 1]\n",
        "\n",
        "X_train_0 = X_train[y_train == 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a6vOcBE3c5x"
      },
      "source": [
        "> Step 2: Compute $\\textbf{b}$ and $c$ from the training set\n",
        "- To compute these, we need to compute 5 things:\n",
        " - $\\textbf{m}_1, \\textbf{m}_0, \\textbf{K}_1, \\textbf{K}_0, \\tau$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFReS1gz3c5x",
        "outputId": "6a716ee3-724c-41ce-b315-361e47531b7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((30, 30), (30, 30))"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Gives the means of all the features for class 1 (malignant) in the training set\n",
        "m_1 = np.mean(X_train_1, axis=0)\n",
        "\n",
        "# Gives the means of all the features for class 0 (malignant) in the training set\n",
        "m_0 = np.mean(X_train_0, axis=0)\n",
        "\n",
        "# Gives the covariance of all the features for class 1 (malignant) in the training set\n",
        "K_1 = np.cov(X_train_1, rowvar=False)\n",
        "\n",
        "# Gives the covariance of all the features for class 0 (benign) in the training set\n",
        "K_0 = np.cov(X_train_0, rowvar=False)\n",
        "\n",
        "K_1.shape, K_0.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdbb48pz3c5x"
      },
      "source": [
        "- To compute $\\textbf{b}$, we need to compute $\\textbf{K}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8Fu5B713c5x",
        "outputId": "8d5dbbf6-79ed-4a72-9ebb-65637523b3b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "289"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_1 = X_train_1.shape[0]\n",
        "n_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ji0DT123c5x",
        "outputId": "4f1a1935-471b-4af0-9dbf-b2594621cc97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "166"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_0 = X_train_0.shape[0]\n",
        "n_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQRSvmou3c5x",
        "outputId": "2752c04d-85a2-45e7-bc84-340a69d3a552"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30, 30)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "K = (n_1 * K_1 + n_0 * K_0)/(n_1 + n_0)\n",
        "K.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UmVJPwI3c5y",
        "outputId": "67e86651-b54b-45f4-c8f7-e8f8f0bb3838"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30,)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = -2*(np.linalg.pinv(K)@m_1 - np.linalg.pinv(K)@m_0)\n",
        "b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzDfZ5Dv3c5y",
        "outputId": "234d641a-ab47-4f98-e51a-fc182a35c16d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-95.59010112046677"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_1 = len(y_train[y_train == 1])/len(y_train)\n",
        "p_0 = len(y_train[y_train == 0])/len(y_train)\n",
        "tau = p_1/p_0\n",
        "\n",
        "c = m_1.T@np.linalg.pinv(K)@m_1 - m_0.T@np.linalg.pinv(K)@m_0 - 2*np.log(tau)\n",
        "c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgd9BaPn3c5y"
      },
      "source": [
        "> Step 3: we need to evaluate the following for each element in the test set:\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{b}^\\top\\textbf{x} + c \\mathop{\\lessgtr}_{y=0}^{y=1} 0\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuv3wL8a3c5y"
      },
      "outputs": [],
      "source": [
        "y_predicted_lda = []\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "    x_i = X_test.iloc[i,:]\n",
        "    \n",
        "    linear_func = b.T@x_i + c\n",
        "    \n",
        "    if linear_func > 0:\n",
        "        predicted = 0\n",
        "    else:\n",
        "        predicted = 1\n",
        "        \n",
        "    y_predicted_lda.append(predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0-gqoka3c5y"
      },
      "source": [
        "> Step 4: We now compute the accuracy of our predictions on the test set `y_test`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogMBrhV73c5y",
        "outputId": "4aca972f-9d42-4eda-a9c3-32e54e19971e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9385964912280702"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diff = y_predicted_lda - y_test # y_test is the true labels from the holdout or test set\n",
        "\n",
        "len(diff[diff==0])/len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyoQHd4n3c5z"
      },
      "source": [
        "> ***93.86% accuracy!***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bwfHFJrx8nT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBvSZX_Af6yk"
      },
      "source": [
        "## Maximum Likelihood Estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHOctvPt3c5z"
      },
      "source": [
        "> Consider a set of independent and identically distributed (iid) observations from a (univariate) Gaussian distribution\n",
        "\n",
        "- $x_1, x_2, ..., x_n$\n",
        "\n",
        "> What is the maximum likelihood estimates of the distribution parameters?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvjk_zFa3c5z"
      },
      "source": [
        "$x_i\\sim N(\\mu, \\sigma^2)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxgMEDJQ3c5z"
      },
      "source": [
        "> Maximum likelihood estimates:\n",
        "- $\\hat{\\mu}$\n",
        "- $\\hat{\\sigma}^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wi7Fba-3c5z"
      },
      "source": [
        "> Probability density function (pdf)\n",
        "\n",
        "\\begin{equation}\n",
        "f(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf4M-xjf3c5z"
      },
      "source": [
        "> Likelihood of the data $L$:\n",
        "\n",
        "\\begin{equation}\n",
        "L = p(x_1, x_2, ..., x_n | \\mu, \\sigma^2)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5y-Ke6U3c5z"
      },
      "source": [
        "> Because samples are independent (iid):\n",
        "\n",
        "\\begin{equation}\n",
        "L = \\prod_{i=1}^n p(x_i | \\mu, \\sigma^2)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZJ7qt3nFZ1o"
      },
      "source": [
        "> Substituting the Gaussian pdf:\n",
        "\n",
        "\\begin{equation}\n",
        "L = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{1}{2\\sigma^2}(x_i-\\mu)^2}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg6a3Y_y3c50"
      },
      "source": [
        "> We can simplify as:\n",
        "    \n",
        "\\begin{equation}\n",
        "L = \\bigg(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\bigg)^n \\prod_{i=1}^n e^{-\\frac{1}{2\\sigma^2}(x_i-\\mu)^2}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "L = \\bigg(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\bigg)^n e^{-\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i-\\mu)^2}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwRprLVs3c50"
      },
      "source": [
        "> We can take logs:\n",
        "\n",
        "\\begin{equation}\n",
        "\\log L = n \\log{\\frac{1}{\\sqrt{2\\pi\\sigma^2}}} -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i-\\mu)^2\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dxT3_wE3c50"
      },
      "source": [
        "### Maximum likelihood estimate of $\\mu$:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YhK2IH93c50"
      },
      "source": [
        "> What value of $\\mu$ maximises the log-likelihood?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZigSkUd3c50"
      },
      "source": [
        "> To maximise a function, a necessary condition is to differentiate and equate to zero:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKtAv2zF9AH"
      },
      "source": [
        "\\begin{equation}\n",
        "\\log L = n \\log{\\frac{1}{\\sqrt{2\\pi\\sigma^2}}} -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i-\\mu)^2\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQejRfG13c50"
      },
      "source": [
        "\\begin{equation}\n",
        "\\frac{\\partial \\log L}{\\partial \\mu} = \\frac{1}{\\sigma^2}\\sum_{i=1}^n (x_i - \\mu) = 0\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEbtZWj83c50"
      },
      "source": [
        "\\begin{equation}\n",
        "\\sum_{i=1}^n (x_i - \\mu) = 0\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\sum_{i=1}^n x_i = \\sum_{i=1}^n \\mu = n\\mu\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n x_i\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBx2Bu1l3c50"
      },
      "source": [
        "### Maximum likelihood estimate of $\\sigma^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx5qWzbg3c51"
      },
      "source": [
        "> What value of $\\sigma$ maximises the log-likelihood?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNpGHy1y3c51"
      },
      "source": [
        "\\begin{equation}\n",
        "\\log L = n \\log{\\frac{1}{\\sqrt{2\\pi\\sigma^2}}} -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i-\\mu)^2\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdqIcgfO3c51"
      },
      "source": [
        "> This can be simplified as:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGmm6___3c51"
      },
      "source": [
        "\\begin{equation}\n",
        "\\log L = n\\log{\\frac{1}{\\sqrt{2\\pi}}} - n\\log{\\sigma} -\\frac{\\sigma^{-2}}{2} \\sum_{i=1}^n (x_i-\\mu)^2\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txtQeSAN3c51"
      },
      "source": [
        "> To maximise a function, a necessary condition is to differentiate and equate to zero:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9jrIEQJ3c51"
      },
      "source": [
        "\\begin{equation}\n",
        "\\frac{\\partial \\log L}{\\partial \\sigma} = -\\frac{n}{\\sigma} + \\sigma^{-3} \\sum_{i=1}^n (x_i - \\mu)^2 = 0\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTa5-lcJ3c51"
      },
      "source": [
        "> We multiply through by $\\sigma^3:$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYpI5bGB3c51"
      },
      "source": [
        "\\begin{equation}\n",
        "-n\\sigma^2 + \\sum_{i=1}^n (x_i - \\mu)^2 = 0\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7fKjuyy3c52"
      },
      "source": [
        "\\begin{equation}\n",
        "\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i - \\mu)^2\n",
        "\\end{equation}\n",
        "\n",
        "** Biased estimate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blEOB31ngDys"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YksDSn6z3c52"
      },
      "source": [
        "> Machine Learning\n",
        "\n",
        "- Feature vector $\\textbf{x}$\n",
        "- Target label $y$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj_Yxr9B3c52"
      },
      "source": [
        "> $h: \\mathcal{X} \\longmapsto \\mathcal{y}$\n",
        "\n",
        "> Probably Approximately Correct (PAC)\n",
        "\\begin{equation}\n",
        "P(| h(\\textbf{x}_{test}) - f(\\textbf{x}_{test}) | < \\epsilon) > p\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sGP_cLk3c52"
      },
      "source": [
        "> Classification (binary)\n",
        "\n",
        "> $p(y=1|\\textbf{x})$ vs $p(y=0|\\textbf{x})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdAAOiLMHdZm"
      },
      "source": [
        "> Now, we're going to assume $y$ is a random variable, following a Bernouilli distribution!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fxXvUFC3c52"
      },
      "source": [
        "### Bernouilli trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKxYVIuO3c52"
      },
      "source": [
        "> Random event with two possible outcomes $y$, e.g., from a coin: $y \\in \\{0, 1\\}$\n",
        "- Heads (1)\n",
        "- Tails (0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gogRx1s3c52"
      },
      "source": [
        "> Fair coin\n",
        "\n",
        "- $p(y = 1) = 0.5$\n",
        "- $p(y = 0) = 0.5$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKuo9akd3c52"
      },
      "source": [
        "> Biased coin\n",
        "\n",
        "- $p(y = 1) = q$\n",
        "- $p(y = 0) = 1-q$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVXl1fYx3c53"
      },
      "source": [
        "> Assumption: Independent Bernouilli trials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtQHRs893c53"
      },
      "source": [
        "> For each $\\textbf{x}_i$ in the training set `X_train`, there is an associated $q_i$, so that\n",
        "\n",
        "- $p(y_i = 1| \\textbf{x}_i) = q_i$\n",
        "- $p(y_i = 0| \\textbf{x}_i) = 1 - q_i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2uoeadI3c53"
      },
      "source": [
        "> The value of $q_i$ depends on what features $\\textbf{x}_i$ we're given"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f--dIOF63c53"
      },
      "source": [
        "### Logistic function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XssZgvLYIG08"
      },
      "source": [
        "> How do we get the probability $q_i$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOkrfq0n3c53"
      },
      "source": [
        "> First, consider a linear combination of the features\n",
        "\n",
        "\\begin{equation}\n",
        "z_i = w_0 + w_1x_1 + w_2x_2 + ... + w_dx_d = \\textbf{w}^\\top\\textbf{x}_i\n",
        "\\end{equation}\n",
        "\n",
        "where:\n",
        "\\begin{equation}\n",
        "\\textbf{w} = [w_0, w_1, w_2, ..., w_d]\n",
        "\\end{equation}\n",
        "\n",
        "and \n",
        "\\begin{equation}\n",
        "\\textbf{x}_i = [1, x_1, x_2, ..., x_d]\n",
        "\\end{equation}\n",
        "\n",
        "> This includes a constant term $w_0$!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq8kXSj23c53"
      },
      "source": [
        "> We now pass $z_i$ through a logistic function:\n",
        "\\begin{equation}\n",
        "q_i = \\frac{1}{1+ e^{-z_i}}, \\quad q_i \\in [0, 1]\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u43t93I83c54",
        "outputId": "5cc9e43f-3fcf-418c-9abf-3dfc4bf44ec4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-10.        ,  -9.7979798 ,  -9.5959596 ,  -9.39393939,\n",
              "        -9.19191919,  -8.98989899,  -8.78787879,  -8.58585859,\n",
              "        -8.38383838,  -8.18181818,  -7.97979798,  -7.77777778,\n",
              "        -7.57575758,  -7.37373737,  -7.17171717,  -6.96969697,\n",
              "        -6.76767677,  -6.56565657,  -6.36363636,  -6.16161616,\n",
              "        -5.95959596,  -5.75757576,  -5.55555556,  -5.35353535,\n",
              "        -5.15151515,  -4.94949495,  -4.74747475,  -4.54545455,\n",
              "        -4.34343434,  -4.14141414,  -3.93939394,  -3.73737374,\n",
              "        -3.53535354,  -3.33333333,  -3.13131313,  -2.92929293,\n",
              "        -2.72727273,  -2.52525253,  -2.32323232,  -2.12121212,\n",
              "        -1.91919192,  -1.71717172,  -1.51515152,  -1.31313131,\n",
              "        -1.11111111,  -0.90909091,  -0.70707071,  -0.50505051,\n",
              "        -0.3030303 ,  -0.1010101 ,   0.1010101 ,   0.3030303 ,\n",
              "         0.50505051,   0.70707071,   0.90909091,   1.11111111,\n",
              "         1.31313131,   1.51515152,   1.71717172,   1.91919192,\n",
              "         2.12121212,   2.32323232,   2.52525253,   2.72727273,\n",
              "         2.92929293,   3.13131313,   3.33333333,   3.53535354,\n",
              "         3.73737374,   3.93939394,   4.14141414,   4.34343434,\n",
              "         4.54545455,   4.74747475,   4.94949495,   5.15151515,\n",
              "         5.35353535,   5.55555556,   5.75757576,   5.95959596,\n",
              "         6.16161616,   6.36363636,   6.56565657,   6.76767677,\n",
              "         6.96969697,   7.17171717,   7.37373737,   7.57575758,\n",
              "         7.77777778,   7.97979798,   8.18181818,   8.38383838,\n",
              "         8.58585859,   8.78787879,   8.98989899,   9.19191919,\n",
              "         9.39393939,   9.5959596 ,   9.7979798 ,  10.        ])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z = np.linspace(-10, 10, 100)\n",
        "z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pho-MVu83c54",
        "outputId": "329ead0f-f260-4604-df29-42506d490edb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4.53978687e-05, 5.55606489e-05, 6.79983174e-05, 8.32200197e-05,\n",
              "       1.01848815e-04, 1.24647146e-04, 1.52547986e-04, 1.86692945e-04,\n",
              "       2.28478855e-04, 2.79614739e-04, 3.42191434e-04, 4.18766684e-04,\n",
              "       5.12469082e-04, 6.27124987e-04, 7.67413430e-04, 9.39055039e-04,\n",
              "       1.14904229e-03, 1.40591988e-03, 1.72012560e-03, 2.10440443e-03,\n",
              "       2.57431039e-03, 3.14881358e-03, 3.85103236e-03, 4.70911357e-03,\n",
              "       5.75728612e-03, 7.03711536e-03, 8.59898661e-03, 1.05038445e-02,\n",
              "       1.28252101e-02, 1.56514861e-02, 1.90885420e-02, 2.32625358e-02,\n",
              "       2.83228820e-02, 3.44451957e-02, 4.18339400e-02, 5.07243606e-02,\n",
              "       6.13831074e-02, 7.41067363e-02, 8.92170603e-02, 1.07052146e-01,\n",
              "       1.27951705e-01, 1.52235823e-01, 1.80176593e-01, 2.11963334e-01,\n",
              "       2.47663801e-01, 2.87185901e-01, 3.30246430e-01, 3.76354517e-01,\n",
              "       4.24816868e-01, 4.74768924e-01, 5.25231076e-01, 5.75183132e-01,\n",
              "       6.23645483e-01, 6.69753570e-01, 7.12814099e-01, 7.52336199e-01,\n",
              "       7.88036666e-01, 8.19823407e-01, 8.47764177e-01, 8.72048295e-01,\n",
              "       8.92947854e-01, 9.10782940e-01, 9.25893264e-01, 9.38616893e-01,\n",
              "       9.49275639e-01, 9.58166060e-01, 9.65554804e-01, 9.71677118e-01,\n",
              "       9.76737464e-01, 9.80911458e-01, 9.84348514e-01, 9.87174790e-01,\n",
              "       9.89496155e-01, 9.91401013e-01, 9.92962885e-01, 9.94242714e-01,\n",
              "       9.95290886e-01, 9.96148968e-01, 9.96851186e-01, 9.97425690e-01,\n",
              "       9.97895596e-01, 9.98279874e-01, 9.98594080e-01, 9.98850958e-01,\n",
              "       9.99060945e-01, 9.99232587e-01, 9.99372875e-01, 9.99487531e-01,\n",
              "       9.99581233e-01, 9.99657809e-01, 9.99720385e-01, 9.99771521e-01,\n",
              "       9.99813307e-01, 9.99847452e-01, 9.99875353e-01, 9.99898151e-01,\n",
              "       9.99916780e-01, 9.99932002e-01, 9.99944439e-01, 9.99954602e-01])"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = 1/(1 + np.exp(-z))\n",
        "q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "r2QsfXAD3c54",
        "outputId": "40a31859-91bf-4e61-b626-17ff35ec0094"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(z, q, 'b')\n",
        "plt.grid(True)\n",
        "plt.xlabel('z_i')\n",
        "plt.ylabel('q_i')\n",
        "plt.title('Logistic function')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn51R1NT3c54"
      },
      "source": [
        "> We have parameterised $q_i$ by some vector of weights $\\textbf{w}$, given $\\textbf{x}_i$:\n",
        "\n",
        "\\begin{equation}\n",
        "q_i = \\frac{1}{1+ e^{-\\textbf{w}^\\top\\textbf{x}_i}}, \\quad q_i \\in [0, 1]\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St-49FXI3c54"
      },
      "source": [
        "> If we knew $\\textbf{w}$, we'd know $q_i$, and since $q_i$ is a probability, we can make predictions as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "y_i = \n",
        "\\begin{cases}\n",
        "1, \\quad q_i \\geq 0.5\\\\\n",
        "0, \\quad q_i < 0.5\n",
        "\\end{cases}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUx0oxOQ3c54"
      },
      "source": [
        "> Using $\\textbf{x}_i, y_i$ from the training set `X_train`, our task is to find the optimal $\\textbf{w}$ that maximises the likelihood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA5TtWTe3c54"
      },
      "source": [
        "### Maximum likelihood estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec1K9-WI3c55"
      },
      "source": [
        "> Likelihood $L$:\n",
        "\n",
        "\\begin{equation}\n",
        "L = \\prod_{i=1}^n p(y_i | \\textbf{x}_i, \\textbf{w})\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWMoI1FN3c55"
      },
      "source": [
        "> Probability mass function (pmf) for the Bernouilli distribution:\n",
        "\n",
        "\\begin{equation}\n",
        "f(y_i; q_i) = \n",
        "\\begin{cases}\n",
        "q_i, \\quad\\quad y_i = 1\\\\\n",
        "1 - q_i, \\quad y_i = 0\n",
        "\\end{cases}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKYgenW23c55"
      },
      "source": [
        "> This can be rewritten as:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqcykkfe3c55"
      },
      "source": [
        "\\begin{equation}\n",
        "f(y_i; q_i) = q_i^{y_i} (1-q_i)^{1-y_i}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AWAA6zm3c55"
      },
      "source": [
        "> Likelihood $L$\n",
        "- Given $\\textbf{x}_i, \\textbf{w}$ we know $q_i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkTzF-2k3c55"
      },
      "source": [
        "\\begin{equation}\n",
        "L = \\prod_{i=1}^n p(y_i | \\textbf{x}_i, \\textbf{w}) = \\prod_{i=1}^n q_i^{y_i} (1-q_i)^{1-y_i}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9fX7hCe3c55"
      },
      "source": [
        "> For computational reasons, we can take logs:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXVlPJ3R3c55"
      },
      "source": [
        "\\begin{equation}\n",
        "\\log L  = \\sum_{i=1}^n \\log {\\big[q_i^{y_i} (1-q_i)^{1-y_i}\\big]}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDBHaIO_3c56"
      },
      "source": [
        "> This can be simplified as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\log L  = \\sum_{i=1}^n y_i \\log {q_i} +  (1-y_i)\\log{(1-q_i)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0bar0iZ3c56"
      },
      "source": [
        "> Recall that:\n",
        "    \n",
        "\\begin{equation}\n",
        "q_i = \\frac{1}{1+ e^{-\\textbf{w}^\\top\\textbf{x}_i}}, \\quad q_i \\in [0, 1]\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVa18xFreUWT"
      },
      "source": [
        "> So, we want to maximise the log likelihood wrt $\\textbf{w}$ which is given in $q_i$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tTuN5Gr3c56"
      },
      "source": [
        "\\begin{equation}\n",
        "\\max_{\\textbf{w}} \\sum_{i=1}^n y_i \\log {q_i} +  (1-y_i)\\log{(1-q_i)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBYvKFgL3c56"
      },
      "source": [
        "> Maximising a function = minimising negative of the function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XryQ5c5O3c56"
      },
      "source": [
        "\\begin{equation}\n",
        "\\min -\\sum_{i=1}^n y_i \\log {q_i} +  (1-y_i)\\log{(1-q_i)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6022qgBTesTl"
      },
      "source": [
        "> If we divide by the number of training examples $n$, the minimisation problem doesn't change:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqoSHliF3c56"
      },
      "source": [
        "\\begin{equation}\n",
        "\\min \\frac{1}{n}\\sum_{i=1}^n -y_i \\log {q_i} - (1-y_i)\\log{(1-q_i)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow_kuCIBf2fg"
      },
      "source": [
        "> We define $J$ as a loss function given as:\n",
        "\n",
        "\\begin{equation}\n",
        "J = \\frac{1}{n} \\sum_{i=1}^n -y_i \\log {q_i} - (1-y_i)\\log{(1-q_i)} =  \\frac{1}{n} \\sum_{i=1}^n J_i\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rrsc17ln3c56"
      },
      "source": [
        "> In information theory, we define entropy $E$ for a Bernouilli random trial as:\n",
        "\n",
        "\\begin{equation}\n",
        "E(y) = -P(y=1)\\log(P(y=1)) - P(y=0)\\log(P(y=0))\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlZR8S2J3c56"
      },
      "source": [
        "> This compares with each term in our loss function $J_i$:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8baI1LeT3c57"
      },
      "source": [
        "> But there is a difference...\n",
        "\n",
        "- Instead of:\n",
        "    \n",
        "\\begin{equation}\n",
        "-y_i \\log (y_i) - (1-y_i) \\log (1-y_i)\n",
        "\\end{equation}\n",
        "\n",
        "- we have:\n",
        "\\begin{equation}\n",
        "J_i = -y_i \\log (q_i) - (1-y_i) \\log (1-q_i)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nFz7pYi3c57"
      },
      "source": [
        "> Entropy between two probability distributions over the same sample space\n",
        "- Hence $J_i$ is a *cross*-entropy!\n",
        "\n",
        "> $J$ is termed the cross-entropy loss\n",
        "- Standard loss function in many neural networks!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heMJbr1dkVNx"
      },
      "source": [
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6SaCf0P3c57"
      },
      "source": [
        "> Differentiate the cross entropy loss $J$ wrt $\\textbf{w}$ and equate to $\\textbf{0}$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IJTl9ld3c57"
      },
      "source": [
        "\\begin{equation}\n",
        "J = \\frac{1}{n}\\sum_{i=1}^n -y_i \\log {q_i} - (1-y_i)\\log{(1-q_i)} = \\frac{1}{n}\\sum_{i=1}^n J_i\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "q_i = \\frac{1}{1+ e^{-z_i}}, \\quad q_i \\in [0, 1]\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "z_i = \\textbf{w}^\\top\\textbf{x}_i\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TVjzZtG3c57"
      },
      "source": [
        "> Chain rule:\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial J}{\\partial \\textbf{w}^\\top} = \\frac{1}{n}\\sum_{i=1}^n \\frac{\\partial J_i}{\\partial q_i}\\times \\frac{\\partial q_i}{\\partial z_i} \\times \\frac{\\partial z_i}{\\partial \\textbf{w}^\\top}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-oBxE213c57"
      },
      "source": [
        "\\begin{equation}\n",
        "\\frac{\\partial J_i}{\\partial q_i} = -\\frac{y_i}{q_i} + \\frac{1-y_i}{1-q_i} = \\frac{q_i - y_i}{q_i(1-q_i)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnwx3m0v3c57"
      },
      "source": [
        "\\begin{equation}\n",
        "q_i = \\frac{1}{1+ e^{-z_i}} = (1+ e^{-z_i})^{-1}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial q_i}{\\partial z_i} = \\frac{e^{-z_i}}{(1+e^{-z_i})^2}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6poHcorM3c58"
      },
      "source": [
        "\\begin{equation}\n",
        "\\frac{\\partial q_i}{\\partial z_i} = \\frac{e^{-z_i}}{1+e^{-z_i}}\\times\\frac{1}{1+e^{-z_i}} = \\frac{e^{-z_i}}{1+e^{-z_i}}q_i\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsKzUWO13c58"
      },
      "source": [
        "> Furthermore, notice that\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{e^{-z_i}}{1+e^{-z_i}} = 1 - q_i\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL-6X3iX3c58"
      },
      "source": [
        "> Therefore,\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial q_i}{\\partial z_i} = q_i(1-q_i)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6dvjYB33c58"
      },
      "source": [
        "> Finally, since:\n",
        "    \n",
        "\\begin{equation}\n",
        "z_i = \\textbf{w}^\\top\\textbf{x}_i,\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial z_i}{\\partial \\textbf{w}^\\top} = \\textbf{x}_i\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eB3Y-s-3c58"
      },
      "source": [
        "\\begin{equation}\n",
        "\\frac{\\partial J}{\\partial \\textbf{w}^\\top} = \\frac{1}{n}\\sum_{i=1}^n \\frac{q_i - y_i}{q_i(1-q_i)} \\times q_i(1-q_i) \\times \\textbf{x}_i\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPFsSzke3c58"
      },
      "source": [
        "> This can be simplified as:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2urBW9U53c58"
      },
      "source": [
        "\\begin{equation}\n",
        "\\frac{\\partial J}{\\partial \\textbf{w}^\\top} = \\frac{1}{n}\\sum_{i=1}^n (q_i - y_i) \\textbf{x}_i\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIyCr6Qq3c58"
      },
      "source": [
        "> We cannot easily solve for $\\textbf{w}$ in closed-form, by equating to $\\textbf{0}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Z1qzEE3c58"
      },
      "source": [
        "> ... instead, we take an iterative approach, starting from some arbitrary initial value:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN9nhVtZgAXC"
      },
      "source": [
        "### Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na8oBCAJeCCJ"
      },
      "source": [
        "> To minimise a function, we take steps in the negative direction of the gradient:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATKu_BZ33c59"
      },
      "source": [
        "\\begin{equation}\n",
        "\\textbf{x}^{(t+1)} = \\textbf{x}^{(t)} - \\alpha \\nabla_{\\textbf{x}}(\\textbf{x}^{(t)})\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-r-Uulq3c59"
      },
      "source": [
        "> $\\alpha$ is the learning rate\n",
        "\n",
        "> $\\nabla_{\\textbf{x}}$ is the gradient of the function wrt $\\textbf{x}$\n",
        "\n",
        "> $t$ is some time index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etwLcVPm3c59"
      },
      "source": [
        "> Example:\n",
        "- Minimise $f(x) = (x-3)^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6K2MHF23c59"
      },
      "source": [
        "\\begin{align}\n",
        "& \\frac{\\partial f}{\\partial x} = 2(x-3) = 0 \\\\\n",
        "& x = 3\n",
        "\\end{align}\n",
        "\n",
        "- Minimum value is $f=0$, and the minimum occurs at $x=3$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnlKpaAY3c59"
      },
      "source": [
        "> Gradient:\n",
        "\n",
        "\\begin{equation}\n",
        "\\nabla_x = \\frac{d f}{d x} = 2(x-3)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hQGVxkk3c59"
      },
      "source": [
        "\\begin{equation}\n",
        "x^{(t+1)} = x^{(t)} - \\alpha \\nabla_x(x^{(t)})\n",
        "\\end{equation}\n",
        "\n",
        "> Starting from some arbitrary initial value $x^{(0)}$:\n",
        "\n",
        "\\begin{equation}\n",
        "x^{(1)} = x^{(0)} - \\alpha \\nabla_x(x^{(0)})\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "x^{(2)} = x^{(1)} - \\alpha \\nabla_x(x^{(1)})\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "x^{(3)} = x^{(2)} - \\alpha \\nabla_x(x^{(2)})\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\vdots\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxjkq86cpovT"
      },
      "source": [
        "#### Gradient descent code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsVpnnp13c59"
      },
      "source": [
        "> $x^{(t)}$ = `x_current`\n",
        "\n",
        "> $x^{(t+1)}$ = `x_next`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSXXM-JV3c59",
        "outputId": "9c8f3f71-a3e5-4a9e-e958-6a2f6dfb9666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.0000000028518503 1.270789093588244e-17\n"
          ]
        }
      ],
      "source": [
        "alpha = 0.1 #learning rate\n",
        "\n",
        "x_current = 17 #Initialisation to some random value\n",
        "\n",
        "x_list = []\n",
        "function_value_list = []\n",
        "\n",
        "for r in range(100):\n",
        "    \n",
        "    function_value = (x_current-3)**2\n",
        "    function_value_list.append(function_value)    \n",
        "    x_list.append(x_current)\n",
        "    \n",
        "    # Update rule\n",
        "    gradient = 2*(x_current-3)\n",
        "    x_next = x_current - alpha*gradient\n",
        "    \n",
        "    #Update current x\n",
        "    x_current = x_next\n",
        "    \n",
        "print(x_current, function_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "nVQD3niZ3c5-",
        "outputId": "1b28aa64-7cd3-46a1-fae6-db3ea9994dcd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(function_value_list, 'ro-')\n",
        "plt.grid(True)\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('function value')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc5RqhOfzLlf"
      },
      "source": [
        "> The function $f(x) = (x-3)^2$ is convex.\n",
        "- Therefore, starting from any random initial value would converge to the same final solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K60e_hgY3c5-"
      },
      "source": [
        "> Logistic regression\n",
        "\n",
        "- Cross entropy loss $J$:\n",
        "\n",
        "\\begin{equation}\n",
        "\\min J = \\frac{1}{n}\\sum_{i=1}^n -y_i \\log {q_i} - (1-y_i)\\log{(1-q_i)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8dJeXF43c5-"
      },
      "source": [
        "\\begin{equation}\n",
        "\\textbf{w}^{(t+1)} = \\textbf{w}^{(t)} - \\alpha \\nabla_{\\textbf{w}}(\\textbf{w}^{(t)})\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI4-Rf7l3c5-"
      },
      "source": [
        "\\begin{equation}\n",
        "\\nabla_{\\textbf{w}} = \\frac{\\partial J}{\\partial \\textbf{w}^\\top} = \\frac{1}{n}\\sum_{i=1}^n (q_i - y_i) \\textbf{x}_i\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biz-RXf63c5-"
      },
      "source": [
        "### Logistic regression code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcrMV2Hw3c5-"
      },
      "source": [
        "> Step 1: Normalise the training set `X_train` by subtracting the mean and dividing by the standard deviation:\n",
        "\n",
        "- Normalisation tends to speed up gradient descent, can improve accuracy, and avoids certain computational issues "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "qU-nZhOb3c5-",
        "outputId": "88a68dd5-3311-4202-8188-3c5221bb0ba2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c020b40a-fdb1-4abf-b059-081afd52ee99\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>11.81</td>\n",
              "      <td>17.39</td>\n",
              "      <td>75.27</td>\n",
              "      <td>428.9</td>\n",
              "      <td>0.10070</td>\n",
              "      <td>0.05562</td>\n",
              "      <td>0.02353</td>\n",
              "      <td>0.01553</td>\n",
              "      <td>0.1718</td>\n",
              "      <td>0.05780</td>\n",
              "      <td>0.1859</td>\n",
              "      <td>1.9260</td>\n",
              "      <td>1.011</td>\n",
              "      <td>14.47</td>\n",
              "      <td>0.007831</td>\n",
              "      <td>0.008776</td>\n",
              "      <td>0.01556</td>\n",
              "      <td>0.006240</td>\n",
              "      <td>0.03139</td>\n",
              "      <td>0.001988</td>\n",
              "      <td>12.57</td>\n",
              "      <td>26.48</td>\n",
              "      <td>79.57</td>\n",
              "      <td>489.5</td>\n",
              "      <td>0.1356</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>0.08803</td>\n",
              "      <td>0.04306</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.06576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>11.36</td>\n",
              "      <td>17.57</td>\n",
              "      <td>72.49</td>\n",
              "      <td>399.8</td>\n",
              "      <td>0.08858</td>\n",
              "      <td>0.05313</td>\n",
              "      <td>0.02783</td>\n",
              "      <td>0.02100</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.05913</td>\n",
              "      <td>0.1916</td>\n",
              "      <td>1.5550</td>\n",
              "      <td>1.359</td>\n",
              "      <td>13.66</td>\n",
              "      <td>0.005391</td>\n",
              "      <td>0.009947</td>\n",
              "      <td>0.01163</td>\n",
              "      <td>0.005872</td>\n",
              "      <td>0.01341</td>\n",
              "      <td>0.001659</td>\n",
              "      <td>13.05</td>\n",
              "      <td>36.32</td>\n",
              "      <td>85.07</td>\n",
              "      <td>521.3</td>\n",
              "      <td>0.1453</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.18110</td>\n",
              "      <td>0.08698</td>\n",
              "      <td>0.2973</td>\n",
              "      <td>0.07745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>14.40</td>\n",
              "      <td>26.99</td>\n",
              "      <td>92.25</td>\n",
              "      <td>646.1</td>\n",
              "      <td>0.06995</td>\n",
              "      <td>0.05223</td>\n",
              "      <td>0.03476</td>\n",
              "      <td>0.01737</td>\n",
              "      <td>0.1707</td>\n",
              "      <td>0.05433</td>\n",
              "      <td>0.2315</td>\n",
              "      <td>0.9112</td>\n",
              "      <td>1.727</td>\n",
              "      <td>20.52</td>\n",
              "      <td>0.005356</td>\n",
              "      <td>0.016790</td>\n",
              "      <td>0.01971</td>\n",
              "      <td>0.006370</td>\n",
              "      <td>0.01414</td>\n",
              "      <td>0.001892</td>\n",
              "      <td>15.40</td>\n",
              "      <td>31.98</td>\n",
              "      <td>100.40</td>\n",
              "      <td>734.6</td>\n",
              "      <td>0.1017</td>\n",
              "      <td>0.1460</td>\n",
              "      <td>0.14720</td>\n",
              "      <td>0.05563</td>\n",
              "      <td>0.2345</td>\n",
              "      <td>0.06464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>15.61</td>\n",
              "      <td>19.38</td>\n",
              "      <td>100.00</td>\n",
              "      <td>758.6</td>\n",
              "      <td>0.07840</td>\n",
              "      <td>0.05616</td>\n",
              "      <td>0.04209</td>\n",
              "      <td>0.02847</td>\n",
              "      <td>0.1547</td>\n",
              "      <td>0.05443</td>\n",
              "      <td>0.2298</td>\n",
              "      <td>0.9988</td>\n",
              "      <td>1.534</td>\n",
              "      <td>22.18</td>\n",
              "      <td>0.002826</td>\n",
              "      <td>0.009105</td>\n",
              "      <td>0.01311</td>\n",
              "      <td>0.005174</td>\n",
              "      <td>0.01013</td>\n",
              "      <td>0.001345</td>\n",
              "      <td>17.91</td>\n",
              "      <td>31.67</td>\n",
              "      <td>115.90</td>\n",
              "      <td>988.6</td>\n",
              "      <td>0.1084</td>\n",
              "      <td>0.1807</td>\n",
              "      <td>0.22600</td>\n",
              "      <td>0.08568</td>\n",
              "      <td>0.2683</td>\n",
              "      <td>0.06829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>12.86</td>\n",
              "      <td>18.00</td>\n",
              "      <td>83.19</td>\n",
              "      <td>506.3</td>\n",
              "      <td>0.09934</td>\n",
              "      <td>0.09546</td>\n",
              "      <td>0.03889</td>\n",
              "      <td>0.02315</td>\n",
              "      <td>0.1718</td>\n",
              "      <td>0.05997</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>1.778</td>\n",
              "      <td>20.35</td>\n",
              "      <td>0.005293</td>\n",
              "      <td>0.016610</td>\n",
              "      <td>0.02071</td>\n",
              "      <td>0.008179</td>\n",
              "      <td>0.01748</td>\n",
              "      <td>0.002848</td>\n",
              "      <td>14.24</td>\n",
              "      <td>24.82</td>\n",
              "      <td>91.88</td>\n",
              "      <td>622.1</td>\n",
              "      <td>0.1289</td>\n",
              "      <td>0.2141</td>\n",
              "      <td>0.17310</td>\n",
              "      <td>0.07926</td>\n",
              "      <td>0.2779</td>\n",
              "      <td>0.07918</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c020b40a-fdb1-4abf-b059-081afd52ee99')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c020b40a-fdb1-4abf-b059-081afd52ee99 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c020b40a-fdb1-4abf-b059-081afd52ee99');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "188        11.81         17.39  ...          0.3200                  0.06576\n",
              "410        11.36         17.57  ...          0.2973                  0.07745\n",
              "462        14.40         26.99  ...          0.2345                  0.06464\n",
              "263        15.61         19.38  ...          0.2683                  0.06829\n",
              "79         12.86         18.00  ...          0.2779                  0.07918\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydwf72Pp3c5-"
      },
      "source": [
        "\\begin{equation}\n",
        "x_{norm} = \\frac{x - \\text{mean}(x)}{\\text{std}(x)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy5LJyZX3c5-",
        "outputId": "1c8ad16d-60a8-4fb1-ade5-6c2a16222150"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.65238694, -0.44142417, -0.68260368, ..., -1.07418807,\n",
              "         0.47291357, -1.05270857],\n",
              "       [-0.78110421, -0.39924004, -0.79814053, ..., -0.40446421,\n",
              "         0.10694113, -0.36818868],\n",
              "       [ 0.0884525 ,  1.80839586,  0.02308545, ..., -0.88251164,\n",
              "        -0.90552889, -1.11829132],\n",
              "       ...,\n",
              "       [-0.41211469, -0.25862629, -0.37422834, ...,  0.41469714,\n",
              "         0.52127997,  1.14548448],\n",
              "       [ 1.56155023,  2.22554999,  1.74159225, ...,  1.22897889,\n",
              "        -0.14295195,  0.98152762],\n",
              "       [ 1.13249264, -0.73202592,  1.18468799, ...,  1.47448331,\n",
              "         1.36124315,  1.58465464]])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "\n",
        "X_train_norm = scaler.transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "X_train_norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc-Cbo1S3c5-"
      },
      "source": [
        "> Step 2: Introduce a column of ones for the constant term in the logistic regression network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhlThPOOtJVM"
      },
      "source": [
        "- Recall that:\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{x}_i = [1, x_1, x_2, ..., x_d]\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{w} = [w_0, w_1, w_2, ..., w_d]\n",
        "\\end{equation}\n",
        "\n",
        "- so that:\n",
        "\n",
        "\\begin{equation}\n",
        "z_i = \\textbf{w}^\\top\\textbf{x}_i = w_0 + w_1x_1 + w_2x_2 + ... + w_dx_d\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdFGLbNz3c5_",
        "outputId": "7f77fad1-5c47-4622-b42c-a778590563f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.        , -0.65238694, -0.44142417, ..., -1.07418807,\n",
              "         0.47291357, -1.05270857],\n",
              "       [ 1.        , -0.78110421, -0.39924004, ..., -0.40446421,\n",
              "         0.10694113, -0.36818868],\n",
              "       [ 1.        ,  0.0884525 ,  1.80839586, ..., -0.88251164,\n",
              "        -0.90552889, -1.11829132],\n",
              "       ...,\n",
              "       [ 1.        , -0.41211469, -0.25862629, ...,  0.41469714,\n",
              "         0.52127997,  1.14548448],\n",
              "       [ 1.        ,  1.56155023,  2.22554999, ...,  1.22897889,\n",
              "        -0.14295195,  0.98152762],\n",
              "       [ 1.        ,  1.13249264, -0.73202592, ...,  1.47448331,\n",
              "         1.36124315,  1.58465464]])"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_norm = np.hstack((np.ones([X_train.shape[0],1]), X_train_norm))\n",
        "X_test_norm = np.hstack((np.ones([X_test.shape[0],1]), X_test_norm))\n",
        "X_train_norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I62uYtZu3c5_"
      },
      "source": [
        "> Step 3: On the normalised training set `X_train_norm`, find the optimal $\\textbf{w}$ by gradient descent on the cross-entropy loss $J$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3am966r3c5_"
      },
      "source": [
        "\\begin{equation}\n",
        "\\textbf{w}^{(t+1)} = \\textbf{w}^{(t)} - \\alpha \\nabla_{\\textbf{w}}(\\textbf{w}^{(t)})\n",
        "\\end{equation}\n",
        "\n",
        "> $\\textbf{w}^{(t)}$ = `w_current`\n",
        "\n",
        "> $\\textbf{w}^{(t+1)}$ = `w_next`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ra0C1D-V3c5_"
      },
      "outputs": [],
      "source": [
        "alpha = 0.1 #learning rate\n",
        "\n",
        "n = X_train_norm.shape[0]\n",
        "\n",
        "w_current = np.ones([d+1,1])/(d+1) #Initialisation\n",
        "#w_current = np.random.normal(size=(d+1,1))\n",
        "\n",
        "function_value_list = []\n",
        "\n",
        "for r in range(1000):\n",
        "    \n",
        "    epsilon = 0\n",
        "    gradient = 0\n",
        "    for i in range(n):\n",
        "        x_i = X_train_norm[i,:].reshape(-1,1)\n",
        "        y_i = y_train.iloc[i]\n",
        "        z_i = (w_current.T@x_i)[0][0]\n",
        "        q_i = 1/(1 + np.exp(-z_i))\n",
        "        \n",
        "        epsilon_i = -y_i*np.log(q_i) - (1-y_i)*np.log(1-q_i)\n",
        "        epsilon = epsilon + epsilon_i\n",
        "        \n",
        "        gradient_i = (q_i - y_i)*x_i\n",
        "        gradient = gradient + gradient_i\n",
        "        \n",
        "    gradient = gradient/n #average gradient\n",
        "    epsilon = epsilon/n #average cross entropy loss\n",
        "    \n",
        "    function_value_list.append(epsilon)\n",
        "    \n",
        "    # Update rule\n",
        "    w_next = w_current - alpha*gradient\n",
        "    \n",
        "    #Update current solution\n",
        "    w_current = w_next.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "8GsKpX0q3c5_",
        "outputId": "787f7cbd-988a-4eec-f526-e62fd8a901b6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(function_value_list, 'ro-')\n",
        "plt.grid(True)\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('function value')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSKidLa03c5_",
        "outputId": "9b57c5af-be5d-40cc-b1fe-e7300643c2c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.62288639],\n",
              "       [-0.5030248 ],\n",
              "       [-0.59619043],\n",
              "       [-0.48689386],\n",
              "       [-0.55526859],\n",
              "       [-0.1585328 ],\n",
              "       [ 0.10391224],\n",
              "       [-0.59228705],\n",
              "       [-0.73117124],\n",
              "       [-0.14054694],\n",
              "       [ 0.31517439],\n",
              "       [-0.98231342],\n",
              "       [ 0.06873686],\n",
              "       [-0.74277646],\n",
              "       [-0.7529556 ],\n",
              "       [ 0.27971529],\n",
              "       [ 0.59754358],\n",
              "       [ 0.20518218],\n",
              "       [-0.03642098],\n",
              "       [ 0.17742197],\n",
              "       [ 0.58092075],\n",
              "       [-0.84051739],\n",
              "       [-0.82561677],\n",
              "       [-0.77439454],\n",
              "       [-0.8235339 ],\n",
              "       [-0.59245236],\n",
              "       [-0.24470498],\n",
              "       [-0.64460381],\n",
              "       [-0.8343082 ],\n",
              "       [-0.62062191],\n",
              "       [-0.27621256]])"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w_current"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOkScgMa3c5_"
      },
      "source": [
        "> Step 4: Once we have learned the optimal value `w_current`, we can test the model on `X_test_norm` by evaluating the following:\n",
        "\n",
        "\\begin{equation}\n",
        "z_i = \\textbf{w}_{current}^\\top\\textbf{x}_i\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "q_i = \\frac{1}{1+ e^{-z_i}}, \\quad q_i \\in [0, 1]\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "y_i = \n",
        "\\begin{cases}\n",
        "1, \\quad q_i \\geq 0.5\\\\\n",
        "0, \\quad q_i < 0.5\n",
        "\\end{cases}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pH-w8Bxw3c5_"
      },
      "outputs": [],
      "source": [
        "y_predicted_lr = []\n",
        "\n",
        "for i in range(X_test_norm.shape[0]):\n",
        "    x_i = X_test_norm[i,:]\n",
        "    \n",
        "    z_i = w_current.T@x_i\n",
        "    \n",
        "    q_i = 1/(1+np.exp(-z_i))\n",
        "    \n",
        "    if q_i >= 0.5:\n",
        "        predicted = 1\n",
        "    else:\n",
        "        predicted = 0\n",
        "        \n",
        "    y_predicted_lr.append(predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6FDFRB83c6A"
      },
      "source": [
        "> Step 5: We now compute the accuracy of the predictions against the test set `y_test`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WII9R6ZF3c6A",
        "outputId": "a9852ac6-3ea0-46d6-ae7b-b20c16512b49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9736842105263158"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diff = y_predicted_lr - y_test # y_test is the true labels from the holdout or test set\n",
        "\n",
        "len(diff[diff==0])/len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SftKLW_B3c6A"
      },
      "source": [
        "> ***97.37% accuracy!***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5qSBjnu3c6A"
      },
      "source": [
        "## Introduction to Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVF2co843c6A"
      },
      "source": [
        "> Logistic regression is a single-layer neural network!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inHOWSzM065T"
      },
      "source": [
        "> Why do we need multiple layers?\n",
        "- To introduce more parameters to allow learning more complex decision boundaries/ functions\n",
        "- To extract more informative features from the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioef0QYv3c6A"
      },
      "source": [
        "> Diagram a 2-hidden-layer network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DLDKWEh3c6A"
      },
      "source": [
        "### Loss function and backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMecTRFP3c6A"
      },
      "source": [
        "> How does the loss function look like?\n",
        "\n",
        "> Binary classification\n",
        "- Cross-entropy loss\n",
        "\n",
        "> Multiclass classification\n",
        "- (Sparse) categorical cross-entropy loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFs7eHJk3c6A"
      },
      "source": [
        "\\begin{equation}\n",
        "J = \\frac{1}{n}\\sum_{i=1}^n -y_i \\log {q_i} - (1-y_i)\\log{(1-q_i)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-D27eTb3c6B"
      },
      "source": [
        "#### Gradient (chain rule):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZRfJ9Vr3c6B"
      },
      "source": [
        "> For logistic regression:\n",
        "    \n",
        "\\begin{equation}\n",
        "\\frac{\\partial J}{\\partial \\textbf{w}^\\top} = \\frac{1}{n}\\sum_{i=1}^n \\frac{\\partial J_i}{\\partial q_i}\\times \\frac{\\partial q_i}{\\partial z_i} \\times \\frac{\\partial z_i}{\\partial \\textbf{w}^\\top}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNJZWjGv3c6B"
      },
      "source": [
        "> For multi-layer perceptron:\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial J}{\\partial \\textbf{w}^\\top} = \\frac{1}{n}\\sum_{i=1}^n \\frac{\\partial J_i}{\\partial z_i^{(4)}}\\times \\frac{\\partial z_i^{(4)}}{\\partial q_i^{(3)}}\\times \\frac{\\partial q_i^{(3)}}{\\partial z_i^{(3)}} \\times \\frac{\\partial z_i^{(3)}}{\\partial q_i^{(2)}} \\times \\frac{\\partial q_i^{(2)}}{\\partial z_i^{(2)}} \\times \\frac{\\partial z_i^{(2)}}{\\partial \\textbf{w}^\\top}\n",
        "\\end{equation}\n",
        "- Backpropagation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-fbCnLM3c6B"
      },
      "source": [
        "> Once we have the gradients, we perform gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewcnVqZ93c6B"
      },
      "source": [
        "> If we started from different initial solutions in the gradient descent, would we converge to the same solution?\n",
        "\n",
        "- Logistic regression: yes\n",
        "\n",
        "- Multi-layer network: no"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh1Z0Dx43c6B"
      },
      "source": [
        "### Convex vs non-convex loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goc0-c-C3c6B"
      },
      "source": [
        "> Convex function:\n",
        "\n",
        "- Has positive semi-definite Hessian matrix\n",
        "- Characterised by one minima"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyD2X8kY9q7U"
      },
      "source": [
        "> Loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4Ym5tcR9BVa"
      },
      "source": [
        "\\begin{equation}\n",
        "J = \\frac{1}{n}\\sum_{i=1}^n -y_i \\log {q_i} - (1-y_i)\\log{(1-q_i)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhltOmoj9E1W"
      },
      "source": [
        "#### Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Erwpx33c6B"
      },
      "source": [
        "- Gradient\n",
        "\\begin{equation}\n",
        "\\nabla_{\\textbf{w}} = \\frac{\\partial J}{\\partial \\textbf{w}^\\top} = \\frac{1}{n}\\sum_{i=1}^n (q_i - y_i) \\textbf{x}_i\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq7Y7yy13c6B"
      },
      "source": [
        "- Hessian\n",
        "\\begin{equation}\n",
        "\\textbf{H} = \\nabla_\\textbf{w}^2 = \\frac{1}{n}\\sum_{i=1}^n q_i(1-q_i) \\textbf{x}_i\\textbf{x}_i^\\top\n",
        "\\end{equation}\n",
        "\n",
        "> This matrix is positive semi-definite\n",
        "\n",
        "- $J$ is convex for logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOlRZ3mn-KJr"
      },
      "source": [
        "#### Multi-layer networks\n",
        "> $J$ is generally non-convex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf5VLqf43c6C"
      },
      "source": [
        "> Implications:\n",
        "\n",
        "- Non-convex functions may be characterised by multiple local minima\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{w}^{(t+1)} = \\textbf{w}^{(t)} - \\alpha \\nabla_{\\textbf{w}}(\\textbf{w}^{(t)})\n",
        "\\end{equation}\n",
        "\n",
        "  - Gradient descent gets trapped at optimal solutions not necessarily global optima"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtBp1P1e3c6C"
      },
      "source": [
        "> Solutions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz92ccKB_EAG"
      },
      "source": [
        "- Multiple random restarts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHX8Yld33c6C"
      },
      "source": [
        "- Stochastic gradient descent (SGD)\n",
        "  - de facto standard, when combined with backpropagation\n",
        "\n",
        "> Rather than:\n",
        "\\begin{equation}\n",
        "\\nabla_{\\textbf{w}} = \\frac{\\partial J}{\\partial \\textbf{w}^\\top} = \\frac{1}{n}\\sum_{i=1}^n (q_i - y_i) \\textbf{x}_i\n",
        "\\end{equation}\n",
        "\n",
        "- we have:\n",
        "\\begin{equation}\n",
        "\\nabla_{\\textbf{w}} = \\frac{\\partial J}{\\partial \\textbf{w}^\\top} = (q_i - y_i) \\textbf{x}_i\n",
        "\\end{equation}\n",
        "\n",
        "- for one random training sample at a time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64ABFYabBP4u"
      },
      "source": [
        "> Some properties of SGD:\n",
        "\n",
        "- Can escape local minima due to the stochasticity in the selection of the training data\n",
        "\n",
        "- Computationally efficient for online learning and large training data\n",
        "\n",
        "- On expectation, SGD converges to true gradient descent\n",
        "\n",
        "- We can have mini-batch SGD too, using a subset of the training set at a time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrYrffSjBTn-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CVvtH_rXCJp"
      },
      "source": [
        "## Practice session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ngkM5nmXIKc"
      },
      "source": [
        "### Wisconsin Breast Cancer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znoTEdr3XPM8"
      },
      "source": [
        "> Task 1: Ensure all the code cells in the notebook runs correctly, and your predictive accuracy on the breast cancer diagnosis test is roughly as shown in the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fSOzuegXS6Y"
      },
      "source": [
        "### Handwriting recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBFLEYjbXV23"
      },
      "source": [
        "- Predict the handwritten digit (`0 - 9`) from its image pixel values:\n",
        "\n",
        "https://www.youtube.com/watch?v=FwFduRA_L6Q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9X9hvrQRXHtk"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "-Kv4ZH6BXCul",
        "outputId": "9f3262c4-462b-4513-acaa-a0176a4ce26a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-56424968-b80c-4407-be8d-b11292969c68\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel_0_0</th>\n",
              "      <th>pixel_0_1</th>\n",
              "      <th>pixel_0_2</th>\n",
              "      <th>pixel_0_3</th>\n",
              "      <th>pixel_0_4</th>\n",
              "      <th>pixel_0_5</th>\n",
              "      <th>pixel_0_6</th>\n",
              "      <th>pixel_0_7</th>\n",
              "      <th>pixel_1_0</th>\n",
              "      <th>pixel_1_1</th>\n",
              "      <th>pixel_1_2</th>\n",
              "      <th>pixel_1_3</th>\n",
              "      <th>pixel_1_4</th>\n",
              "      <th>pixel_1_5</th>\n",
              "      <th>pixel_1_6</th>\n",
              "      <th>pixel_1_7</th>\n",
              "      <th>pixel_2_0</th>\n",
              "      <th>pixel_2_1</th>\n",
              "      <th>pixel_2_2</th>\n",
              "      <th>pixel_2_3</th>\n",
              "      <th>pixel_2_4</th>\n",
              "      <th>pixel_2_5</th>\n",
              "      <th>pixel_2_6</th>\n",
              "      <th>pixel_2_7</th>\n",
              "      <th>pixel_3_0</th>\n",
              "      <th>pixel_3_1</th>\n",
              "      <th>pixel_3_2</th>\n",
              "      <th>pixel_3_3</th>\n",
              "      <th>pixel_3_4</th>\n",
              "      <th>pixel_3_5</th>\n",
              "      <th>pixel_3_6</th>\n",
              "      <th>pixel_3_7</th>\n",
              "      <th>pixel_4_0</th>\n",
              "      <th>pixel_4_1</th>\n",
              "      <th>pixel_4_2</th>\n",
              "      <th>pixel_4_3</th>\n",
              "      <th>pixel_4_4</th>\n",
              "      <th>pixel_4_5</th>\n",
              "      <th>pixel_4_6</th>\n",
              "      <th>pixel_4_7</th>\n",
              "      <th>pixel_5_0</th>\n",
              "      <th>pixel_5_1</th>\n",
              "      <th>pixel_5_2</th>\n",
              "      <th>pixel_5_3</th>\n",
              "      <th>pixel_5_4</th>\n",
              "      <th>pixel_5_5</th>\n",
              "      <th>pixel_5_6</th>\n",
              "      <th>pixel_5_7</th>\n",
              "      <th>pixel_6_0</th>\n",
              "      <th>pixel_6_1</th>\n",
              "      <th>pixel_6_2</th>\n",
              "      <th>pixel_6_3</th>\n",
              "      <th>pixel_6_4</th>\n",
              "      <th>pixel_6_5</th>\n",
              "      <th>pixel_6_6</th>\n",
              "      <th>pixel_6_7</th>\n",
              "      <th>pixel_7_0</th>\n",
              "      <th>pixel_7_1</th>\n",
              "      <th>pixel_7_2</th>\n",
              "      <th>pixel_7_3</th>\n",
              "      <th>pixel_7_4</th>\n",
              "      <th>pixel_7_5</th>\n",
              "      <th>pixel_7_6</th>\n",
              "      <th>pixel_7_7</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56424968-b80c-4407-be8d-b11292969c68')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56424968-b80c-4407-be8d-b11292969c68 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56424968-b80c-4407-be8d-b11292969c68');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   pixel_0_0  pixel_0_1  pixel_0_2  ...  pixel_7_6  pixel_7_7  target\n",
              "0        0.0        0.0        5.0  ...        0.0        0.0       0\n",
              "1        0.0        0.0        0.0  ...        0.0        0.0       1\n",
              "2        0.0        0.0        0.0  ...        9.0        0.0       2\n",
              "3        0.0        0.0        7.0  ...        0.0        0.0       3\n",
              "4        0.0        0.0        0.0  ...        0.0        0.0       4\n",
              "\n",
              "[5 rows x 65 columns]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "digits_object = load_digits(n_class = 10, as_frame=True)\n",
        "df = digits_object.data\n",
        "df['target'] = digits_object.target\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzbYQd_QXfVv"
      },
      "outputs": [],
      "source": [
        "df_06 = df[(df['target'] == 0) | (df['target'] == 6)]\n",
        "df_17 = df[(df['target'] == 1) | (df['target'] == 7)]\n",
        "df_23 = df[(df['target'] == 2) | (df['target'] == 3)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hfaN7ifXjW_"
      },
      "source": [
        "> Task 2: Build a model (NB, QDA, LDA, LR) to predict handwritten digits: \n",
        "- `0` vs `6`: use `df_06`\n",
        "- `1` vs `7`: use `df_17`\n",
        "- `2` vs `3`: use `df_23`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf0g5ujiXlkW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Machine_Learning_Seminar.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}